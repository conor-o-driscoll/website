[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Conor O'Driscoll",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nERSA 2025: Some Reflections\n\n\n\n\n\nMy thoughts and reflections on the 65th annual conference of the European Regional Science Association.\n\n\n\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nDifferent Types of Data: Part 2\n\n\n\n\n\nQualitative or Quantitative? Nominal, Ordinal, Interval, and Ratio.\n\n\n\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\nDifferent Types of Data: Part 1\n\n\n\n\n\nInternal and External. Primary and Secondary.\n\n\n\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is Data?\n\n\n\n\n\nData describe the universe we wish to study.\n\n\n\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nWhat Is Statistics?\n\n\n\n\n\nstatistics is how we learn from evidence.\n\n\n\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nThinking Statistically: A Primer\n\n\n\n\n\nThinking statistically doesn’t start with numbers or formulas, it starts with noticing.\n\n\n\n\n\n12 min\n\n\n\n\n\n\n\n\n\n\n\n\nHow to write a thesis in 1000 words or less\n\n\n\n\n\nAre you struggling to write your thesis?\n\n\n\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nAlways visualise your data: Simpsons Paradox in action\n\n\n\n\n\nWhat if the data you’re analyzing tells one story in aggregate—but the exact opposite when you break it down?\n\n\n\n\n\n10 min\n\n\n\n\n\n\n\n\n\n\n\n\nStart Young, Drive Less: The Overlooked Power of the School-Run\n\n\n\n\n\nWhat if the key to transforming urban mobility isn’t the daily commute—but how we get our kids to school?\n\n\n\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is the cost of commuting?\n\n\n\n\n\nHave you ever wondered how much your daily commute costs you? This post may provide you with some answers.\n\n\n\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to my website!\n\n\n\n\n\nWelcome to my website! This post describes what you can expect to find on this platform and how I intend to use it.\n\n\n\n\n\n2 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "CV.html",
    "href": "CV.html",
    "title": "Curriculum Vitae: Download pdf here",
    "section": "",
    "text": "Personal Profile\nAssistant Professor in The University of Groningen’s Department of Economic Geography. Main fields of interest include Economic Geography, Regional Science, Urban Economics, and Transportation Science. Proficient in spatial analysis which employs advanced econometric techniques (STATA, QGIS, and R).\n\n\nEducation\n\nPhD: Economics\nDepartment of Economics, University College Cork, Ireland\nOctober 2020 – September 2023\n\nDissertation Title: Urban Sprawl: Land-Use, Travel Behaviours, and Emissions in Ireland\nSupervisors: Prof. Justin Doran, Dr. Frank Crowley, Dr. Nóirín McCarthy\nPhD Committee: Prof. Aisling Reynolds-Feighan (UCD), Dr. John Eakins (UCC), Dr. Edward Lahiff (UCC)\n\n\n\nBA: Economics and History\nUniversity College Cork, Ireland\nSeptember 2017 – September 2020\n\nGrade: Upper Second-Class Honours (3.33–3.67 GPA)\nMinor Dissertation: First-Class Honours (4.0 GPA)\n\n\n\n\nEmployment History\n\nAssistant Professor in Economic Geography\nFaculty of Spatial Sciences, University of Groningen, The Netherlands\nOctober 2023 – Present\n\n\nSenior Demonstrator in Economics\nCentre for Policy Studies, University College Cork, Ireland\nSeptember 2022 – June 2023\n\n\nTeaching Assistant in Economics\nDepartment of Economics, University College Cork, Ireland October 2020 – June 2023\n\n\nPostgraduate Tutor in Business, Social Sciences, and Public Policy\nSkills Centre, University College Cork, Ireland\nJune 2021 – June 2023\n\n\nResearch Assistant\nDepartment of Economics, University College Cork, Ireland April 2021 – July 2022; July 2023 – September 2023\n\n\n\nTeaching Experience\n\nEconomic Geography\n\n2024–: Economic Geography: Theory and Practice (MSc)\n2023–: Economic Geography (BSc)\n\n\n\nStatistics / Econometrics / Quantitative Research Methods\n\n2023–: Introductory Statistics (BSc); Intermediate Statistics (BSc); Quantitative Research Methods (BSc).\n2020-2023: Data Collection, Analysis, and Interpretation (BA); Quantitative Research Methods (BA); Mathematics For Business (BComm); Research in Economics (BA).\n\n\n\nEconomics\n\n2020-2023: Introductory Microeconomics (BSc, BComm, BA); Intermediate Microeconomics (BComm, BA); Introductory Macroeconomics (BSc, BComm, BA); Intermediate Macroeconomics (BComm, BA); Economics and Social Issues (BComm, BA); Economics and Labour Markets (BComm); Money and Monetary Policy (BComm).\n\n\n\nResearch Supervision\n\nPhD Proposals [2]; MSc Dissertations [14]; Undergraduate Dissertations/Projects [25].\n\n\n\n\nAccolades and Honours\n\n2023: Postgraduate Researcher of The Year (2021-2022)\nCollege of Business and Law, University College Cork, Ireland\n\n\n2022: Best Paper by an Early Career Researcher - Honourable Mention\nRegional Science Association International: British and Irish Section\n\n\n\nGrants and Funding Awards\n\n2025:\nUniversity of Groningen PhD Starter Grant co-funded by Talent in de Regio (€300,000 + €50,000) With Dr. Femke Cnossen and Prof. Sierdjan Koster\n\n\n2023:\nCork University Business School Travel Bursary (€800) University College Cork, Department of Economics Conference Bursary (€400)\n\n\n2022:\nUCC Department of Economics Conference Bursary (€400)\n\n\n2021:\nUCC Department of Economics Conference Bursary (€450)\n\n\n\nAffiliations and Professional Service\n\nResearch Affiliations\n\nResearch Affiliate\nRudolf Agricola School for Sustainable Development, University of Groningen January 2025 – Present\n\n\nResearch Associate\nThe Urban and Regional Studies Institute, University of Groningen October 2023 – Present\n\n\nResearch Associate\nSpatial and Regional Economic Research Centre, University College Cork October 2020 – Present\n\n\n\nEditorial Positions\n\nChief Editor of The Boolean\nJune 2021 – September 2023\n\n\n\nReferee Services\nJournal of Transport and Land-Use, Transportation Research Interdisciplinary Perspectives, Journal of Geographical Systems, Urban Climate, The Boolean, The Spatial and Regional Economic Research Centre PhD Development Series.\n\n\nProfessional Memberships\n\nWorld Society of Transport and Land Use Research\n2025 – Present\n\n\nRegional Studies Association\n2023 – Present\n\n\nRegional Science Association International\n2020 – Present\n\n\n\n\nPublications\n\nOngoing Research Projects\n\nConor O’Driscoll. 2025. “Commuting in Flux: The Roles of Place and Personal Circumstance In Shaping Behavioural Plasticity”.\nConor O’Driscoll and Milad Abbasiharofteh. 2025. “Roots and Routes: Residential Relocation and Relatedness”.\nConor O’Driscoll and Federica Rossi. 2025. “Residential Relocation Decisions and Destinations: The Role of Working From Home”.\nConor O’Driscoll and Ana Maria Silva. 2025. “Working From Home and Labour Market Outcomes: The Case of Earnings and Hours Worked”.\nConor O’Driscoll and Luise Koeppen. 2025. “Subnational Institutional Corruption and Political Discontent”.\nConor O’Driscoll. 2025. “Navigating Change: Residential Relocation, Travel Behaviours, and Built Environments”. Major Revisions in Papers in Regional Science.\n\n\n\nPeer-Reviewed Journal Articles\n\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy; Josh O’Driscoll. 2025. “Travel Behaviours and Built Environments on School-Runs”. Regional Science Policy and Practice, 17(1), pp.1-14. doi: 10.1016/j.rspp.2024.100153.\nKevin Credit and Conor O’Driscoll. 2024. “Assessing Modal Tradeoffs and Associated Built Environment Characteristics Using a Cost-Distance Framework”. Journal of Transport Geography, 117, pp.1-19. doi: 10.1016/j.jtrangeo.2024.103870.\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy. 2024. “The relationships between socio-demographics, residential environments, travel considerations, and commute mode choice in Ireland”. Regional Studies, 58(3), pp.1-18. doi: 10.1080/00343404.2023.2199779.\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy. 2023. “Land-Use Mix in Ireland: Implications for Sustainable Development”. Journal of Maps, 19(1), pp.1-7. doi: 10.1080/17445647.2023.2214165.\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy. 2023. “Land-Use Mixing in Irish Cities: Implications for Sustainable Development”. Land Use Policy, 128(5), pp.1-7. doi: 10.1016/j.landusepol.2023.106615.\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy. 2022. “Retail Sprawl and CO2 Emissions: Retail Centres in Irish Cities”. Journal of Transport Geography, 102(6), pp.1-12. doi: 10.1016/j.jtrangeo.2022.103376.\n\n\n\nIndustry and Policy Reports\n\nJane Bourke; Conor O’Driscoll; Josh O’Driscoll; Páidí O’Reilly. 2022. “Innovating in Ireland: Can We Fail Better?”. Cork University Business School.\n\n\n\nSelect Popular Writings\n\nConor O’Driscoll. 2024. “The Cost of Morning Commutes: The Case of Kildare”. Kildare FM.\nConor O’Driscoll and Kevin Credit. 2024. “Here’s the real cost of your morning rush hour commute in Dublin”. RTE Brainstorm.\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy. 2023. “How the relationship between socio- demographics, residential environments and travel influence commuter choices”. Regional Studies Blog.\nConor O’Driscoll. 2023. “Retail Centre Locations in Cork: The Case of Carrigtwohill”. RTE Prime Time.\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy. 2022. “Planning For Sustainability: Future Retail Centre Locations”. The Boolean, 6(8), pp.27-32.\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy. 2022. “The Links Between Where We Live and How We Commute”. RTE Brainstorm.\nJane Bourke; Josh O’Driscoll; Conor O’Driscoll. 2022. “Does fear of failure hamper Irish business innovation?”. RTE Brainstorm.\nConor O’Driscoll. 2021. “Why out of town retail parks don’t make sense in a climate crisis”. RTE Brainstorm.\nConor O’Driscoll. 2021. “Shopping Malls, GHG Emissions and The Role of Policymakers in”Green” Transportation Infrastructure in Ireland”. Regional Studies Association: Student Summer Series.\n\n\n\n\nMain Conferences and Workshops\n\n2025:\nRegional Science Association International: British and Irish Section; the 64th European Regional Science Association (ERSA) Congress (Scheduled).\n\n\n2024:\nRegional Studies Association: Irish Section; Regional Science Association International: British and Irish Section.\n\n\n2023:\nRegional Science Association International: British and Irish Section; Cork University Business School Postgraduate Symposium.\n\n\n2022:\nRegional Science Association International: British and Irish Section (Session Chair); Cork University Business School Postgraduate Symposium.\n\n\n2021:\nConference of Irish Geographers; Regional Science Association International: British and Irish Section (Organising Committee Member); Cork University Business School Postgraduate Symposium; UCC Spatial and Economic Research Centre Lunchtime Speaker Series; The North American Meetings of The Regional Science Association (Session Chair).\n\n\n\nReferences\n\nProf. Justin Doran: Primary PhD Supervisor and Head of UCC’s Department of Economics. Email: Justin.Doran@ucc.ie.\nProf. Sierdjan Koster: Dean of RUG’s Faculty of Spatial Sciences. Email: sierdjan.koster@rug.nl.\nProf. Frank Crowley: Secondary PhD Supervisor. Email: Frank.Crowley@ucc.ie\nDr. Viktor Venhorst: Associate Professor in RUG’s Department of Economic Geography. Email: v.a.venhorst@rug.nl."
  },
  {
    "objectID": "posts/data.html",
    "href": "posts/data.html",
    "title": "What is Data?",
    "section": "",
    "text": "Statistics and Data: A Refresher\nSometimes, we observe a single thing — a person, a place, an event — and note several of its features. More interestingly, we often observe many things that are similar in some respects but quite different in others. We notice patterns across people, places, or time. We end up with a collection of observations, or, in the language of statistics, data.\n\n\nWhat Is Data?\nAt their simplest, data are pieces of information — observations about the world that we record in some form. A single measurement, like the temperature outside your window at 9 a.m., the price of a coffee, or the number of emails you received yesterday, is a data point. These individual observations can seem small or insignificant on their own, but they become powerful when we begin to organize, compare, and analyze them.\nData are the raw material on which the discipline of statistics is built, as well as the raw material from which individual statistics are calculated. They are how we turn experience into insight. Just as a painter starts with brushstrokes and a sculptor with clay, researchers, policymakers, and businesses start with data. Every chart, table, and model in the world begins with some observation of something, somewhere, at some time.\nWhen most people think of data, they think of numbers — prices, temperatures, test scores, population counts. Numbers are easy to compare, summarize, and analyze, which is why quantitative data dominate most datasets.\nBut data don’t have to be numerical. Words, categories, images, and even sounds can be data if they represent something about the world in a structured way. For example, a survey might record people’s favorite color, a collection of photos could capture land use patterns, or a transcript of an interview could be coded into themes for analysis.\nThe key is that data are representations. They simplify some aspect of reality so we can work with it. Whether numbers or categories, quantitative or qualitative, the purpose is the same: to turn observations into something we can organize, compare, and interpret.\n\n\nFrom Data Points To Datasets\nA single observation rarely tells us much. To understand patterns, we need more than one data point — we need a collection of observations, or a dataset. Datasets allow us to ask questions like: How do house prices vary across neighborhoods? How does rainfall change over the course of a year? How do exam scores differ between schools?\nDatasets give structure to our observations. They let us see variation, compare groups, and detect trends. A few data points can suggest a pattern, but a well-structured dataset allows us to test whether that pattern is real, typical, or just a fluke. It’s the difference between noticing one expensive apartment in a city and understanding the broader reality of housing affordability, for example.\n\n\nMeasurement and Interpretation\nData are not just facts handed down by nature. They are created, measured, and recorded by humans (or human-designed instruments). This introduces choices and interpretations at every stage: What should we measure? How should we measure it? When and where should we record it? Even seemingly simple decisions — like whether to record height in centimeters or inches — can shape the analysis that follows.\nBecause of this, data always carry context. Understanding that context is part of thinking statistically. A number without context can mislead; it’s only by knowing how, why, and under what conditions it was collected that we can use it wisely and interpret it correctly. For example, if you are using survey data, it is important to think about whether everyone asked gave answers to all the questions. If not, is there some systematic bias which might explain why some people answered and others did not? Similarly, we need to know if the data we are using are up to date and whether the instrument use to measure and collect data is reliable.\n\n\nData Quality and Representation\nOne way to look at data is to view it as evidence. Without data, our ideas and theories about the world are little more than speculations. Thus, data provide a grounding, linking our ideas to reality and allowing us to validate and test our understanding.\nNot all data are created equal. Some are precise and reliable; others are messy, inconsistent, or incomplete. Poor-quality data can lead to misleading conclusions, no matter how sophisticated the analysis. Data quality depends on factors such as accuracy, completeness, consistency, and timeliness.\nFor example, consider a dataset of city rental prices. If a few entries are wrong — a typo that lists €10,000 instead of €1,000 — the average rent can be skewed, giving a false impression of affordability. Missing data, such as unreported rents in certain neighborhoods, can bias conclusions. Even the way categories are defined, like “downtown” or “suburban,” can affect what the data seem to show.\nRecognizing the limitations of data is just as important as analyzing the numbers themselves. Good data analysis begins with careful inspection: understanding what is measured, checking for errors, and considering what might be missing.\nThe choices we make in measurement matter. For example, if we measure student performance only through test scores, we ignore other important aspects like creativity, teamwork, or critical thinking. Similarly, using surveys to measure happiness depends on how questions are phrased and who responds. Measurement is never perfect, but careful design can make data useful and meaningful.\nData can also summarize, categorize, and structure information. A dataset may record exact values (e.g., temperature), counts (e.g., number of hospital visits), or categories (e.g., occupation type). The way data are structured influences what we can ask and what conclusions we can draw.\n\n\nWrapping Up\nUltimately, data are the bridge between the world we see and the patterns we try to understand. Individual data points become datasets; datasets reveal variation, relationships, and trends; and careful attention to quality and measurement ensures that the patterns we see are meaningful and trustworthy.\nThinking critically about data — where it comes from, how it was collected, and what it actually represents — is as important as any statistical technique. Raw numbers alone do not explain anything. It is through analysis, comparison, and interpretation that data become insight, guiding decisions, shaping policies, and helping us make sense of complex social, economic, and natural phenomena.\n\n\nBibliography\n\nStatistics: A Very Short Introduction, by David J. Hand"
  },
  {
    "objectID": "posts/thinking.html",
    "href": "posts/thinking.html",
    "title": "Thinking Statistically: A Primer",
    "section": "",
    "text": "Thinking Statistically: A Way of Seeing the World\nMost of us meet statistics in passing — a poll on the evening news, a headline about a medical breakthrough, a sports commentator flashing charts on the screen. We may not think much of it, but statistics quietly runs through almost every part of modern life: from predicting the weather, to setting housing policy, to planning bus timetables. Behind every one of those applications is the same motivation: to make better sense of the world around us, thus helping us to make better decisions in the face of uncertainty.\nFor social and spatial scientists, this work happens in two worlds at once. The visible world (e.g., house prices, commuting patterns, school applicatins) helps us to come up with our own ideas and theories about how the world works. Meanwhile, the world we infer (e.g., migration patterns, economic opportunity, discrimination, and efficiency) is the world we inhabit when we try to link our theories and ideas to reality.\nStatistics sits at the intersection of these two worlds. Without statistics, our ideas and theories about the world around us are little more than speculations. With statistics, we can compare our perceptions of the world to a more grounded view of reality, allowing us to test and validate our own understanding. A poor match between our ideas and reality forces us to think again and reformulate our theories based on what we observe through statistics, while a good match might signal that we have a good intuitive understanding of what is going on.\nImplicit in this is the notion that, in order to be meaningful, our ideas and theories of the world around us must yield plausible predictions; predictions which we can evaluate and assess using statistics. If our theories and ideas to do not tell us what we should expect to observe, or if the predictions are so general that any data will conform with our theories (e.g., astrology), then evidently our theories and ideas are no good.\n\n\nDecision Making and Asking Better Questions\nWith this in mind, statistics is also a valuable tool we can use to steer our way through a complex world and make decisions about the “best” actions to take. We can use statistical methods to extract information from data we have collected to describe how the world is behaving and infer how we might wish to respond. Therefore, statistics plays a fundamental role in tying observations about the world around us to our ideas and understanding of that world, providing a disciplined way to make sense of a messy reality.\nThe kind of thinking involved in Statistics may seem quite different from what you are used to. But once we strip away the jargon and examine what it is we are really doing, you will quickly realize that the kind of thinking involved in statistics is not entirely new to you. In fact, many of your day-to-day assumptions and decisions already depend on statistical thinking.\nWhen we summarize our past experience in a rough-and-ready way, or generalize from previous experiences, and use this information to make predictions about what we expect, we are subconsciously making broader sense of our lived experiences. That is why thinking statistically is not about chasing certainty, it is about navigating ambiguity with discipline. We use data to challenge our assumptions, to explore patterns we might not otherwise see, and to resist being misled by what seems obvious.\n\n\n\n\n\n\nNote\n\n\n\nSuppose I tell you that I have two friends: one is around six feet tall and the other is five feet tall. What would be your best guess as to each one’s sex?\nOf course, you have not seen all men, or all women, but experience probably tells you that by-and-large, men tend to be taller than women.\nTherefore, I expect that you feel fairly confident in assuming that my smaller friend is female, while my taller friend is male. In other words, in the absence of any other information, you probably think it is more likely that a tall adult is male and a small adult is female.\n\n\nWe do this all the time. When you say: “On average, I cycle 50km per week”, or “We can expect a lot of rain at this time of year”, or “It is more likely that you will do well in your exams if you begin studying early” you are making statistical statements even though you have performed no calculations. Indeed, each of these examples is showing off one particular type of statistical thinking; answer the questions below to figure out which.\n\nWhat type of statistical thinking best corresponds to each of the following scenarios:\n\nOn average, I cycle 50km per week. GeneralizingPredictingSummarizingAssessing\nWe can expect a lot of rain at this time of year. GeneralizingPredictingAssessingSummarizing\nIt is more likely that you will do well in your exams if you begin studying early. AssessingPredictingGeneralizingSummarizing\n\n\n\n\nStatistics is human-made\nBecause statistics involve numbers, people often assume they are hard facts handed down by nature. But numbers don’t just fall from the sky — people choose what to count, how to count it, and how to present it. That means statistics are not just facts, they are interpretations.\nTo think statistically is to think critically. It’s to ask questions like: Is that plausible? Compared to what? How do they know? The more you practice, the more these habits become second nature — a kind of internal, healthy skepticism paired with external curiosity.\nThis ability to think critically is become more important everyday. We live in an age where information is instant but trust is fragile. It is becoming increasingly difficult to tell what is true and what is not. Even though misinformation has been a problem that has existed since ancient Greece, the unique problem we face today is that it has proliferated and is closely intertwined on the internet with real information, making it sometimes difficult to identify.\nSome of you who might respond by saying “it is not my job to evaluate statistics critically”. I say that it may not be your job, but it is your responsibility to own your opinions. Taking ownership of these opinions requires you to think critically about the words and numbers you encounter, and scrutinize/examine them as best you can.\nTest your ability to critically evaluate statistical statements using the following examples, where TRUE = Plausible and False = Not Plausible:\n\n\nA crystal wine glass fell off a table onto a thick carpet without breaking. TRUEFALSE\nA crystal wine glass fell off the roof of a forty-storey skyscraper onto the footpath without breaking. TRUEFALSE\nThe best salesperson in Company X makes 1,000 sales every day. TRUEFALSE\nThe cost of a telephone has decreased by 12,000 percent since the formation of the Communication Satellite Corportation. TRUEFALSE\n\n\nProblems 4 and 5 were hopefully easy for most of you.\nProblem 6 is a bit trickier because it is not immediately obvious where to begin. But below I take a stab at it. Not to say that this is the one-and-only way to answer this question, but it is one illustration of how you can apply statistical thinking to assess the plausibility of a statistical statement.\n\n\n\n\n\n\nNote\n\n\n\nAssuming that it takes: i) five seconds to dial a phone number, ii) another five seconds for the phone to ring, iii) 10 seconds to deliver your sales pitch, and iv) 40 seconds to collect the buyers bank details and address. That adds up to one call per minute. Finally, lets assume that every phone call ends in a sale. Even under these highly optimistic conditions, you come out sixty sales per hour, and 480 sales in an eight hour work day with no breaks. Need I say any more?\n\n\nClaim 7 is difficult to verify if you do not spot the immediate contradiction. If a cost decreases by 100 percent it means that, irrespective of the starting price, the price is now zero. If a cost decreases by 200 percent, it means that someone is paying you the same amount of money that you used to pay them for their product. Thus, while a decrease in price of 100 percent is quite rare, a decrease of 12000 percent seems wildly unlikely. You might think this is obvious, but tell that to the editors of Science (a premier scientific journal) who published such a statement.\n\n\n\n\n\n\nNote\n\n\n\nClaim 7 introduces another common error when interpreting statistics and that involves making sense of percentages.\nPercentages seem so simple and incorruptable, but they are often confusing. For example, if your salary drops by 50% tomorrow, you will not “break-even” by increasing your new salary by 50 percent because the baselines have changed.\nIf you were recieving €1,000 each week and that suddenly dropped to €500 (a 50 percent reduction), a 50 percent increase on that pay only brings you to €750.\nSimilarly, if interest rates rise from 3 to 4 percent, that constitutes an increase of one percentage point, or an increase of 33 percent. Meanwhile, if interest rates drop from 4 to 3 percent, that constitutes a decrease of one percentage point, but a decrease of 25 percent. Has your head exploded yet?\n\n\nWorking with percentages and probabilities can be hard even for those of us with advanced degrees in such subjects. So even though we all practice statistical thinking quite regularly, that does not mean we are naturally very good at it.\nIn one somewhat famous case, the state of New Jersey (U.S.A) adopted legislation that denied additional benefits to mothers who have children while already on welfare. Some legislators believed that women were having babies in New Jersey simply to increase the amount on their welfare checks. Within two months, legislators were declaring that the “family cap” law was a success because births had already fallen by 16 percent, as reported in the New York Times. Now, maybe things are different in New Jersey, but I believe that it takes nine months for a pregnancy to come to term, so how can this effect possibly be attributed to the policy?\nBut state legislators are not the only people to make basic blunders in statistical thinking. Experts do it all the time, something demonstrated in the highly impressive Thinking, Fast and Slow by Daniel Kahneman (Nobel Laureate in Economics, 2002).\nOther claims, like More people have cell phones than toilets (reported by Time Magazine in 2013) are a bit trickier because the answer depends on a host of factors, like who/how we count and what we compare. One potentially reasonable place to start in this example might be the observation that many people in the developing world do not have indoor plumbing, whereas many people in the developed world may have more than one cell phone (at least over their lifetime). From this angle, the claim seems plausible. This is not to say that we should accept it, but rather that we cannot reject it out-of-hand as being ridiculous. In this case, what matters isn’t whether you instantly know the answer, but whether you know how to start thinking about solving the problem.\n\n\nShooting the messenger\nImportantly, however, not all misuses of statistics are accidents. In his book A Field Guide To Lies and Statistics, Daniel Levitin (a neuroscientist) provides a number of examples where statistics are mis-used, misinterpreted, or misapplied honestly as well as dishonestly.\nThis hits upon a broader point that sometimes you cannot always determine whether a statistic or claim is reliable. Sure, the people who generate and report on such statistics should do this for you, but they often do not. Sometimes, this is deliberate (i.e., politically-motivated) but other times the people generating/reporting on these statistics do not understand them all that well.\nThat is how runaway statistics take hold, potentially poisoning public opinion and discourse on a particular topic, further emphasizing the importance of being able to think statistically.\nTake the widely reported statistic (from some years ago) that, in the U.S. 150,000 girls and young women die of annorexia each year. According to the U.S. Centers for Disease Control, the annual number of deaths from all causes for girls and women between the ages of fifteen and twenty-four (a reasonable definition for “girls and young women”?) is around 8,500. If you become more conservative in your definitions and incorporate women aged twnety-five to fourty-four, you still only get 55,000. It should be obvious that annorexia deaths in one year cannot be three times the number of all reported deaths, but it clearly was not.\nIn these cases, it is often very easy to blame to blame the statistician or the statistics themselves, but they are usually not the ones with concealed motivations, political or otherwise.\nMoreover, when a statistic is used to measure performance, people often start “playing to the metric” — sometimes in ways that make the number look better without actually improving the thing it’s meant to measure. (Economists call this Goodhart’s Law). National accounting measures like Gross Domestic Product (GDP) are becoming increasingly good examples of i) statistical measures that are gamed for concealed motives and ii) measures which do not do what they say on the tin - which brings us to a whole new level of discussion about picking and understanding your choice of measurement…the subject of another blog.\n\n\nWrapping Up\nStatistics is not just about techniques. It is about developing better instincts and organising your curiosity. It helps you ask clearer questions and give more careful answers.\nIt will not turn you into a calculator. But it will help you see more clearly. To doubt usefully, not cynically. To ask things like: Where did that number come from? What is the comparison? What is the alternative?\nIf you have ever had a hunch something was not quite right, or spotted a pattern in your surroundings, congratulations. You have already started thinking statistically.\n\n\nBibliography\n\nStatistics Without Tears: An Introduction For Non-Mathematicians, by Derek Rowntree\nA Field Guide To Lies and Statistics: A Neuroscientist on How to Make Sense of A Complex World, by Daniel J. Levitin\nElementary Statistics For Geographers by James Burt, Gerald Barber, and David Rigby"
  },
  {
    "objectID": "posts/what_is_stats.html",
    "href": "posts/what_is_stats.html",
    "title": "What Is Statistics?",
    "section": "",
    "text": "Thinking Statistically: A Refresher\nStatistical thinking begins with something very simple: noticing. We notice events, we notice people, we notice differences. We see rents climbing in our city, or hear friends complain about how much they’re paying, and we wonder: is this just a few unlucky cases, or does it say something bigger about the housing market? This is the heart of thinking statistically. It is not about complicated formulas, but about moving from what we observe to what we might reasonably believe about the world. The post Thinking Statistically: A Primer goes into more detail on this point.\n\n\nFrom Observations To Patterns\nSometimes, we observe a single thing — a person, a place, an event — and note several of its features. More interestingly, we often observe many things that are similar in some respects but quite different in others. We notice patterns across people, places, or time. We end up with a collection of observations, or, in the language of statistics, data.\nFaced with such a collection, it is natural to start comparing. What is the same? What is different? What might explain those differences? This is where statistical thinking deepens. The overarching question becomes: what can we learn from this data?\nOne of the great temptations in everyday life is to leap from a vivid example to a sweeping claim. A frustrating encounter with a GP becomes “the NHS is broken.” A handful of pricey flat listings becomes “this city is unaffordable.” But while anecdotes grab attention, they rarely tell the whole story. If we want to understand whether a city is truly unaffordable, for example, we need more than isolated cases: we need patterns.\nThat means gathering many observations and looking for regularities across them. Instead of just noting that a friend’s rent has doubled, we might ask: what are average rents across the city? How do they compare to incomes? How do they vary between neighbourhoods or over time? These “how much” questions — how much bigger, how much more frequent, how much more difficult — are everywhere in daily life, and they are precisely where statistical thinking deepens. We move from anecdotes to collections of observations, and from collections to evidence that can support or challenge our claims.\nThis is why statistics is best understood not as a tool for eliminating uncertainty, but as a way of working productively with it. The numbers never speak for themselves. They help us move from stories to systems, from isolated cases to general patterns.\n\n\nLikelihood and Certainty\nEven with careful observation, we rarely get perfect answers. Instead, we learn to talk in terms of likelihood. At its core, statistical thinking is about likelihood, not certainty. We weigh the chances (i.e., probability). We expect patterns to hold “in general” or “on average” or “in the long run,” but it never promises that every case will follow the rule.\nThis is what makes statistics so powerful for the social sciences. People, places, and societies are complex and unpredictable. But with good data and careful reasoning we can still learn a lot. We can be clear about what we know, open about what we don’t, and realistic about how confident we should be.\nStatistics helps us summarize what we have found so we can be clear about the facts. But it also helps us go further: to compare, to explain, and to predict. It reminds us to be cautious. What appears true in one context may not hold in another, as I am sure you are all acutely aware. Before we can test a hypothesis or quantify uncertainty, we need to know what matters, what varies, and what might be related. This requires a theoretical understanding of the problem you are studying just as much as it requires an understanding of what is happening in your data.\nIf we want to generalize more confidently, the logical starting point is to gather more experience - that is, collect more data. This speaks to the fact that the more contexts, situations, and experiences we observe, the more confident we can be in drawing conclusions and making suggestions. In other words, if we want to generalize more confidently, we need more data, which happens to be the logic underpinning one of the most powerful ideas in statistics: the Central Limit Theorem.\nThinking statistically then, is not about memorising formulas or crunching numbers. It is about developing a habit of mind: noticing variation, looking for patterns, and reasoning in terms of likelihood. Done well, it sharpens our instincts and grounds our judgments. It helps us move beyond stories to understanding, and beyond uncertainty to insight.\nIn that sense, statistics does not replace your instincts. It organizes and strengthens them. You already ask whether something seems off. You already notice patterns. What statistics offers is a way to build on those instincts: to sharpen them, test them, and sometimes correct them. It helps you become more precise in your questions and more careful in your answers. And that is a powerful skill, no matter what field you are in.\n\n\nWhat Is Statistics?\nStatistics is a word that causes confusion, not because it is complicated, but because it has so many meanings. It can refer to a subject of study, to methods of analysing data, to the data themselves, or to the specific numbers we calculate. For example, a researcher might study statistics, use statistics to analyse data, interpret official statistics, and report a statistic like average income. This is partly why, in our statistics courses, we tend to adopt the following definition of statistics:\n\n\n\n\n\n\nImportant\n\n\n\nStatistics is the methodology for collecting, presenting, analysing, and interpreting data.\n\n\nMany students are introduced to statistics so that they can interpret and understand research carried out in their field of interest. But statistics is everywhere — in the news, in sports, in science, in policy, in medicine. Yet it is often misunderstood. Many people see it as dry, overly technical, or even manipulative. Some fear it as a tangle of formulas; others distrust it because numbers can be twisted to tell a story. This suspicion around statistics is understandable. We’ve all seen numbers used to persuade, distract, or deceive. Sometimes statistics are gamed — when a measure becomes a target, it can lose its meaning (Goodhart’s Law). But the problem is rarely the statistics themselves; it’s how they are used, what is being measured, and how we interpret the results.\nIn fact, modern statistics is less about arithmetic and more about reasoning, exploration, and interpretation. Computers handle most calculations today, freeing us to focus on the questions we ask, the assumptions we make, and the conclusions we draw. In that sense, statistics is a technology — a set of tools for extracting meaning from data, for navigating uncertainty, and for learning from evidence.\nAt its core, statistics embraces the imperfection of our observations. We know that any single measurement is flawed; our data are simplified representations of a complex world. Statistics gives us ways to measure and reason through these uncertainties, to understand variation, and to weigh how far wrong we might be. Hence why good statistical thinking matters.\n\n\n\n\n\n\nNote\n\n\n\nThis is why data and statistics are inseparable. Data, often numerical but not always, allow us to represent what we are studying. They are never perfect, but they are workable — and with good judgement, they let us move from noticing patterns to understanding systems. Poor data, of course, lead to poor conclusions irrespective of the tools used.\n\n\n\n\nBibliography\n\nStatistics: A Very Short Introduction, by David J. Hand\nStatistics Without Tears: An Introduction For Non-Mathematicians, by Derek Rowntree\nElementary Statistics For Geographers, by James E. Burt, Gerald M. Barber, and David L. Rigby"
  },
  {
    "objectID": "posts/school_run.html",
    "href": "posts/school_run.html",
    "title": "Start Young, Drive Less: The Overlooked Power of the School-Run",
    "section": "",
    "text": "School-runs are a common but underexamined part of daily mobility. In Ireland, they account for nearly one in five household trips, yet they’re often treated as an extension of the adult commute or folded into broader discussions about household logistics. Our recent study aimed to take the school-run seriously; not just as a variant of commuting, but as a travel behaviour shaped by a distinct set of social, spatial, and infrastructural dynamics.\nDrawing on census data from almost 300,000 secondary school students across Ireland, we linked individual travel behaviour to a range of built environment characteristics. We used Generalised Structural Equation Modelling (GSEM) to capture the direct and indirect relationships between factors like land-use mix, transport infrastructure, household structure, and mode choice. This approach allowed us to unpack how both context and constraint shape how students get to school.\n\nSchool-Runs Are Not Just Commutes with Backpacks\nIn some respects, school-runs mirror adult commuting: students are more likely to walk, cycle, or take public transport when they live closer to school, in more compact neighbourhoods, and in areas with better infrastructure. These patterns align closely with findings from commuting research.\nBut school-runs also reflect the complexity of family routines. Even for secondary students, decisions about how to get to school are influenced by household structures, parental schedules, perceptions of safety, and the presence of siblings. Car-based trip-chaining is common, and family habits around transport tend to carry over across generations.\nRecognising these dynamics helps us move beyond individual preferences and towards a better understanding of the constraints and contexts that shape school travel.\n\n\nWhat We Found\nOur findings can be summarised around three key insights:\nBuilt environment matters. Students living in more mixed-use, compact areas with better walking and transit infrastructure are significantly more likely to use sustainable modes. These effects hold even when we account for household income and other socioeconomic factors.\nDistance remains the strongest determinant. Longer school trips are strongly associated with car use. Students who live and study in the same neighbourhood, especially within the same Electoral Division — are much more likely to walk or take public transport. Travel distance continues to shape the choice set in powerful ways.\nHousehold context matters. Students from more affluent and two-parent households are more likely to be driven to school. While these households may live in areas with good infrastructure, access to a private vehicle seems to override other factors, highlighting the role of habit, convenience, and household coordination.\nWe also found that the structure of the local transport network plays a key role. Areas with denser road networks tended to see higher rates of car use, while greater availability of walking and cycling infrastructure was associated with more active travel. In short, people tend to use the infrastructure that’s available to them.\n\n\nWhy It Matters\nThere is growing policy interest in promoting active travel and reducing car dependency for health, environmental, and congestion reasons. But most interventions still focus on adult commuters. The school-run, by contrast, offers a more consistent and replicable point of intervention. It happens daily, follows predictable routes, and shapes the travel habits of young people.\nWhile behaviour change campaigns are important, our findings suggest that structural conditions, particularly built form, infrastructure quality, and travel distance, remain central to shifting how people move. If we want to support more sustainable school travel, we need to plan for it: shorten distances between home and school, build coherent and safe active travel networks, and improve the quality and reliability of public transport.\nUltimately, school-runs are not just about getting from A to B. They reflect broader spatial, social, and institutional dynamics. Understanding them better can help us build cities that support more inclusive and sustainable forms of everyday mobility.\nFor the full technical details, please check out the full paper here!"
  },
  {
    "objectID": "posts/thesis_1000_words.html",
    "href": "posts/thesis_1000_words.html",
    "title": "How to write a thesis in 1000 words or less",
    "section": "",
    "text": "Take a deep breath\nWriting a thesis can feel overwhelming at first, but it really doesn’t have to be. Whether you’re working on a BSc or MSc thesis, this process should be a rewarding and even enjoyable experience. If done right, it’s one of the few moments in your studies where you get to really take the lead—asking a question you care about and seeing where it takes you.\nStart with something that interests you. This sounds obvious, but it matters. When students are genuinely curious about their topic, the whole process works better. They read more deeply, write more thoughtfully, and engage with feedback more meaningfully. You don’t need a perfect question from the outset, especially at BSc level, but you do need a spark. Something you want to understand better.\n\n\nThe bigger picture\nA good thesis is also one that’s feasible. Big, complex questions are appealing in theory, but they’re rarely manageable within the scope of a student project. The best work I’ve supervised often focuses on one method and one main idea, carried out with clarity and care. It’s better to do something simple well than to do something ambitious halfway.\nAt MSc level, more independence is expected from the start. Students are generally expected to arrive with a clear idea of their topic and to develop a more original contribution to the academic literature. That said, support is still there, and the same principles apply: clarity over complexity, structure over improvisation, and a well-reasoned approach to methods and writing.\nFor BSc students, the process is more structured. The work is often group-based, with staged assignments and regular feedback. This helps students stay on track and provides a useful framework for what, for many, is their first piece of independent research.\nRegardless of level, writing is the central skill. A thesis lives and dies on how well it’s written. This doesn’t mean flowery language or complicated phrasing, it means clear, coherent thinking on the page. Readers shouldn’t have to guess what you mean or how your argument fits together. Every section should do a job, and every paragraph should move the argument forward.\n\n\nThe section-specific details\nThe Abstract should summarise what you studied, how you studied it, and what you found: brief, factual, and to the point.\nThe Introduction needs to make the case for your research: why the topic matters, what the main question is, how you approach it, and how it contributes to the broader literature.\nThe Theoretical Framework should not just list what others have said, but explain how you’re thinking about the topic and what concepts or hypotheses guide your analysis.\nThe Data and Methods section explains what materials you used and how you analysed them. This should be clear enough that someone else could, in theory, replicate what you did independently.\nThe Results section should present your findings clearly and systematically, without overloading the reader; if you include a Discussion here, use it to interpret what those findings mean in light of your research question and theory.\nThe Conclusion ties everything together: what you found, why it matters, what the limitations were, and where the research could go next.\nFormatting, structure, and references matter too, but the real foundation is clarity—of thought, of question, of execution.\n\n\nOwnership and Expectations\nAbove all, take ownership of your work. Supervisors are there to help, but they won’t, and can’t, catch everything. The best students use feedback wisely, plan their time well, and take responsibility for shaping their project. This is your research, and the final thesis should reflect how you think, not just what you did.\nWriting a thesis isn’t just about ticking boxes: it’s about learning how to ask better questions, how to test ideas, and how to communicate your findings. It’s a challenge, yes, but also a rare opportunity. With the right focus and a bit of care, it can be a genuinely rewarding part of your academic life.\n\n\nLooking for more?\nIf you found this post useful, I suggest you check out the fully-fleshed out writing guide that I distribute to all the students under my supervision. You can find it here."
  },
  {
    "objectID": "posts/ersa_2025.html",
    "href": "posts/ersa_2025.html",
    "title": "ERSA 2025: Some Reflections",
    "section": "",
    "text": "Over the past week i had the pleasure of attending the 65th annual conference of the regional science association.\nOverall, the conference was a major success for me. I got to meet some really interesting people, especially: Steven Bond-Smith, Inessa Tregubova, Tuomas Väisänen, Liv Osland, and Lukas Makovsky. But I also got to catch up with some old friends who I seldom see outside of such events.\nThe conference venue was interesting: a run-down university just outside the city centre of Athens (a truly beautiful city, I must stress). There were many many (over 900!) presenters and the sessions were long, so the days were quite intense. But the quality of presentations was, on balance, reasonably high, which facilitated many nice and stimulating discussions on pressing topics for spatial and social scientists. The food at the conference was amazing, culminating in a fabulous dinner in an events centre type-of-place that overlooked the whole city and harbour. It was breathtaking.\nAttending conferences is a super nice opportunity for academics to share and discuss the research they are currently undertaking. In doing so, we usually receive quite helpful feedback on making our projects better, but also get to meet likeminded people who like to think about similar problems. This can lead to potentially exciting collaborations on different research projects, but it more generally allows you to expand your professional network and keep pace with the rapidly developing knowledge base in your respective field.\nAt ERSA, I presented two research papers I am currently working on. The first concerns the relationship between widespread working-from-home adoption and locational mobility. More specifically, Federica Rossi and I explore the relationship between working from home frequently and i) the probability that individuals relocate their residence and ii) the probability of individuals moving to specific types of places (i.e., cities, suburbs, and rural areas).\nThe discussion surrounding this paper was really stimulating, and i had the pleasure of meeting really impressive scholars who are working on tangential issues. The result? Some really nice discussions on i) how to make my current research better and more impactful, and ii) how we might collaborate together on future research projects.\nThe second project is my first solo-authored research paper. The core focus of this paper is to explore the relative importance of local built environments and major life events in shaping commuting behaviour. Theoretically, our understanding of these dynamics is somewhat limited. And I have some pretty cool data that allows me to explore this issue in great detail. So I also applied for the prestigious Epainos award - an award that recognises excellence in early career research.\nUnfortunately, I did not win the award. Inessa Tregubova won the Epainos award in 2025 for her innovative work linking GPS data, working-from-home proclivities, and spatial equilibrium models - a very very cool project. On my end, I received terrific feedback on how I might make my paper more impactful from a theoretical and empirical perspective; and I am hoping to use this feedback to inspire my application for next year’s Epainos award.\nWith a new academic year starting up again, I thought it potentially useful to reflect on my experiences, as it will be many months before I get the opportunity to attend another international conference. Some takeaway points for me are:\n\n2 hour sessions are too long. 90 minutes is just right.\nThere should not be more than 4 presenters in any session.\nSessions dedicated to Young Scientists are an amazing initiative, and it is especially nice that ERSA schedules all such sessions on their own - providing excellent exposure to early career academics.\nI need to become a bit better at i) preparing the narrative of my presentations and ii) planning my presentations so that they are ~5 minutes shorter than the allocated time (delays are inevitable).\nConferences are super fun and i am excited to go to more."
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching and Related Materials",
    "section": "",
    "text": "University of Groningen\n\n\n\nEconomic Geography (MSc)\n\nThis course (GEMEGTT) examines how global trends—such as technological change, climate change, and demographic transitions—affect regions differently, leading to varying economic, social, and environmental outcomes. It focuses on understanding the causes of regional socio-economic inequalities and explores how governments and other actors attempt to address them through policy at different spatial scales.\nThe course has two main aims. First, it introduces students to key theoretical and empirical debates in Economic Geography. Second, it applies these insights to real-world practices in local and regional development. Topics include regional labour markets, entrepreneurship, globalization, and spatial policy tools such as city branding, business incentives, and land-use planning.\nStudents explore both analytical concepts and empirical approaches, with a focus on the interaction between people, firms, policy, and place. The course highlights the role of institutions and governance structures in shaping regional outcomes, and discusses how development paths differ across city regions, intermediate areas, and rural zones.\nA key feature of the course is its applied orientation. Students learn how academic insights relate to practical policy decisions, preparing them for careers in regional development. This includes a study trip to Brussels to engage with institutions involved in EU regional policy.\nBy the end of the course, students are able to analyse complex geographical patterns, understand the relationship between economic and spatial processes, and assess policy responses to regional challenges. They also gain awareness of relevant labour market opportunities and the professional context of economic geographers.\n\n\nRecommended Readings\n\n\nLocal and Regional Development, by Andy Pike, Andrés Rodríguez-Pose, and John Tomaney\nAn Introduction To Geographical and Urban Economics: A Spiky World, by Steven Brakman, Harry Garretsen, and Charles van Marrewijk\nThe New Geography of Jobs, by Enrico Moretti\nTriumph of The City: How Urban Spaces Make Us Human, by Edward Glaeser\nThe Death and Life of Great American Cities, by Jane Jacobs\nOrder Without Design: How Markets Shape Cities, by Alain Bertaud\nGuns, Germs, and Steel: The Fates of Human Societies, by Jared Diamond\nThe Wealth of Cities and The Poverty of Nations, by Christof Parnreiter\nThe Great Convergence: Information Technology and The New Globalisation, by Richard Baldwin\n\n\n\n\n\nStatistics and Quantitative Research Methods (BSc)\n\nThis covers a trilogy of Introduction, Intermediate, and Applied Statistics courses which I currently teach at the University of Groningen. The studens are bachelor students studying Geography, Planning, and Demography. Relevant materials can be made available upon request.\n\nIntroductory Statistics (GESTAT1)\n\nStatistics 1 (GESTAT1) introduces students to a range of descriptive and inferential statistical techniques. Key topics include levels of measurement, spatial and non-spatial sampling, data presentation using tables and figures, and measures of central tendency and dispersion. The course also covers the central limit theorem, z-scores, z-tests, t-tests, non-parametric alternatives, and the binomial test. In addition, it addresses principles of research data management.\nStudents learn to select suitable statistical methods based on variable type and research design, and to apply these techniques using software such as R or a calculator. The course also focuses on interpreting statistical outcomes and reporting on methods, data, and results in a clear and structured manner.\nThroughout the course, attention is given to data quality, measurement accuracy, and validity. Students are expected to assess these factors carefully and apply appropriate techniques for analysis. Practical use of R supports this process, helping students to work with real data in a structured and transparent way.\n\n\nRecommended Readings\n\n\nStatistics: A Very Short Introduction by David J. Hand\nStatistics Without Tears: An Introduction For Non-Mathematicians, by Derek Rowntree\nA Field Guide To Lies and Statistics: A Neuroscientist on How to Make Sense of A Complex World, by Daniel J. Levitin\nThe Uncounted, by Alex Cobham\nElementary Statistics For Geographers by James Burt, Gerald Barber, and David Rigby\n\n\n\nIntermediate Statistics (GESTAT2)\n\nStatistics 2 (GESTAT2) focuses on multivariate statistical techniques and builds on the foundation established in Statistics 1. The course covers key methods including chi-square tests, measures of association, correlation, simple and multiple linear regression, interaction and mediation effects, as well as binary, ordinal, and multinomial logistic regression. The course places emphasis on selecting appropriate uni- and multivariate methods based on the characteristics of variables and the design of the research.\nStudents learn to select suitable statistical methods based on variable type and research design, and to apply these techniques using software such as R or a calculator. The course also focuses on interpreting statistical outcomes and reporting on methods, data, and results in a clear and structured manner.\nThroughout the course, attention is given to data quality, measurement accuracy, and validity. Students are expected to assess these factors carefully and apply appropriate techniques for analysis. Practical use of R supports this process, helping students to work with real data in a structured and transparent way.\n\n\nRecommended Readings\n\n\nMastering ’Metrics: The Path From Cause To Effect, by Joshua D. Angrist and Jörn-Steffan Pischke\nApplied Statistics Using STATA (and R): A Guide For The Social Sciences, by Mehmet Mehmetoglu and Tor Georg Jakobson\nElementary Statistics For Geographers by James Burt, Gerald Barber, and David Rigby\n\n\n\nQuantitative Research Methods (GEASRM)\n\nThis course introduces students to the full process of conducting quantitative research in the field of Spatial Sciences. It covers all stages of the research process, from formulating research questions to data collection, analysis, and presentation of results. Students learn to design and carry out a quantitative survey aligned with a clearly defined research question, using appropriate methods and techniques.\nThe course includes key topics such as data management, research ethics, and scientific integrity, with attention to responsible use of data and tools such as generative AI. Students apply quantitative methods to analyse and interpret data, and are trained to communicate findings effectively using numerical evidence.\nComputer software is used to support data analysis, with a focus on practical application within Spatial Sciences. In addition to individual work, students collaborate in teams to conduct research, with an emphasis on academic standards and constructive teamwork. The course also encourages critical reflection on the research process, data quality, and the validity of conclusions.\n\n\nRecommended Readings\n\n\nMastering ’Metrics: The Path From Cause To Effect, by Joshua D. Angrist and Jörn-Steffan Pischke\nMostly Harmless Econometrics: An Empiricist’s Companion, by Joshua D. Angrist and Jörn-Steffan Pischke\nApplied Statistics Using STATA (and R): A Guide For The Social Sciences, by Mehmet Mehmetoglu and Tor Georg Jakobson\nCausal Inference: The Mixtape, by Scott Cunningham\nThe Book of Why: The New Science of Cause and Effect, by Judea Pearl\nThe Effect: An Introduction To Research Design and Causality, by Nick Huntington-Klein\n\n\n\n\nUniversity College Cork\n\n\n\nStatistics and Econometrics (BSc)\n\nThis covers a series of courses I taught at University College Cork. The content relates to undergraduate statistics and econometrics, and was taught to students studying economics, finance, and commerce. Relevant materials can be made available upon request.\n\nIntroductory Statistics (BSc)\n\nThese courses start with introductions to descriptive statistics, inferential statistics, and probability. Much of this learning focuses on how these subjects relate to business practices. Students are introduced to elementary calculus, the mathematics of finance, differentiation, matrix algebra, alongside exponential, logarithmic, and polynomial functions. Students use this knowledge to calculate elasticities, solve for equilibria, and work with series and annuities.\nFrom there, a major emphasis is placed on the practical application of statistics to business contexts. Teaching centres around the practicalities of working with data. Students are exposed to key software used for analysing economic and financial data, such as Excel and STATA. They are also tasked with collecting, analysing, interpreting, and presenting economic data in written reports. Supplementing this are introductions to the numerous types of economic and financial data available, and the outlets from which these data can be acquired.\nIn University College Cork, I have been involved in the following courses which fit this description in different capacities:\nEC1111 (Economic Data Collection) EC1200 (Quantitative Techniques For Economics 1) EC1209 (Understanding and Interpreting Data) MA1100 (Introductory Mathematics For Business)\n\n\nRecommended Readings\n\n\nStatistics: A Very Short Introduction by David J. Hand\nStatistics Without Tears: An Introduction For Non-Mathematicians, by Derek Rowntree\nA Field Guide To Lies and Statistics: A Neuroscientist on How to Make Sense of A Complex World, by Daniel J. Levitin\nThe Uncounted, by Alex Cobham\nWhy Most Things Fail, by Paul Ormerod\nElementary Statistics For Geographers by James Burt, Gerald Barber, and David Rigby\n\n\n\nIntermediate Statistics and Introductory Econometrics (BSc)\n\nThese courses build upon foundational statistics and probability knowledge by equipping students with the skills to critically evaluate economic research, data, methods, and findings. This is supplemented by introductions to hypothesis testing and statistical inference using cross-sectional and time-series methods.\nFrom there, students are exposed to the relationships between economic theory and practice, and how different modelling techniques can be applied to different scenarios within a business context. In particular, simple linear regression, multiple linear regression, functional forms, and variable transformations are introduced while assessment emphasizes the interpretation of findings and implications of using different empirical techniques.\nIn University College Cork, I have been involved in the following courses which fit this description in different capacities:\nEC1210 (Skills For Analysing Economic Data) EC2015 (Research in Economics) EC2116 (Introduction To Statistical Economic Analysis) EC2206 (Business Econometrics and Forecasting) EC4215 (Business Econometrics 1) Excel and STATA material\n\n\nRecommended Readings\n\n\nMastering ’Metrics: The Path From Cause To Effect, by Joshua D. Angrist and Jörn-Steffan Pischke\nMostly Harmless Econometrics: An Empiricist’s Companion, by Joshua D. Angrist and Jörn-Steffan Pischke\nEconometrics By Example, by Damodar Gujarati\nIntroductory Econometrics: A Modern Approach, by Jeffrey Wooldridge\nRegression Models For Categorical Dependent Variables Using STATA, by Scott Long and Jeremy Freese\nApplied Statistics Using STATA (and R): A Guide For The Social Sciences, by Mehmet Mehmetoglu and Tor Georg Jakobson\nCausal Inference: The Mixtape, by Scott Cunningham\nProbability and Statistics For Economists, by Bruce Hansen\nThe Effect: An Introduction To Research Design and Causality, by Nick Huntington-Klein\nThe Book of Why: The New Science of Cause and Effect, by Judea Pearl\nFooled By Randomness: The Hidden Role of Chance in Life and in The Markets, by Nassim Nicholas Taleb\nThe Black Swan: The Impact of The Highly Improbable, by Nassim Nicholas Taleb\nSkin In The Game: Hidden Asymmetries in Daily Life, by Nassim Nicholas Taleb\nAntifragile: Things That Gain From Disorder, by Nassim Nicholas Taleb\n\n\nAlongside these reading materials, I have also produced Introductory Guides and Practical Materials for STATA and Excel which can be made available upon request. Topics covered include:\n\nDescriptive Statistics and Data Visualisation (STATA, Excel, and R)\nMoving Averages and Forecasting (Excel)\nSimple and Multiple Linear Regression (STATA and R)\nVariable Transformations and Functional Forms (STATA and R)\nBinary, Multinomial, and Ordinal Logistic Regression (R)\n\n\n\n\nMacroeconomics (BSc)\n\nThis covers a series of courses I taught at University College Cork. The content relates to undergraduate macroeconomics, and was taught to students studying economics, finance, and commerce. Relevant materials can be made available upon request.\n\nIntroductory Macroeconomics\n\nThese courses start with the study of the economy as a whole, focusing on aggregate measures such as national income, unemployment, inflation, and economic growth. Students learn to work with theories of supply and demand, fiscal and monetary policy, international trade, and exchange rates, while also covering national income accounting, the measurement of economic activity, and the circular flow of income.\nThe role of government in influencing economic outcomes is also explored. Topics such as fiscal policy, monetary policy, and the role of central banks are discussed, along with the challenges and trade-offs involved in implementing macroeconomic policies. This provides students with opportunities to apply theoretical concepts to analyze current economic events and policy debates, enhancing their critical thinking and analytical skills.\nIn University College Cork, I have been involved in the following courses which fit this description in different capacities:\nEC1116 (Introductory Macroeconomics) EC1208 (Principles of the Macro Economy) EC1503 (Economic Analysis for Food Business) EC1122 (Markets, Governments and the Economics of Social Issues)\n\n\nRecommended Readings\n\n\nThe Great Economists: How Their Ideas Can Help Us Today, by Linda Yueh\nHow To Think Like An Economist, by Robbie Mochrie.\nCan’t We Just Print More Money? Economics in Ten Simple Questions, by Jack Meaning\nThe Great Crashes: Lessons From Global Meltdowns and How To Prevent Them, by Linda Yueh\nGlobalization and Its Discontents, by Joseph Stiglitz\nDoughnut Economics, by Kate Raworth\nGood Economics For Hard Times: Better Answers To Our Biggest Problems, by Abhijit V. Banergee and Esther Duflo\nPoor Economics, by Abhijit V. Banergee\nNature, Culture, and Inequality, by Thomas Picketty\nA Brief History of Equality, by Thomas Picketty\nWhy Nations Fail: The Origins of Power, Prosperity, and Poverty, by Daron Acemoglu and James A. Robinson\n\n\n\nIntermediate Macroeconomics\n\nThese courses build upon the work done in introductory modules by focusing on specific themes and issues within macroeconomics. Themes and topics studied include human capital, inequality, money and monetary policy, alongside national and international economic variables which affect business performance.\nSome of these courses then pivot to focus on social issues and policy, thereby requiring detailed analysis of issues like healthcare, pensions, and the welfare state, while some of these courses focus on financial markets. An overarching theme in these courses, however, is the role of governmental intervention in the economy alongside how Ireland is situated in the global macroeconomic environment. This provides students with opportunities to apply theoretical concepts to analyze current economic events and policy debates, enhancing their critical thinking and analytical skills.\nIn University College Cork, I have been involved in the following courses which fit this description in different capacities:\nEC2010 (The Changing Economy: Money and Monetary Policy) EC2112 (Macroeconomics: Irish and International Business Cycles) EC2151 (Economics of Social Policy 1) EC2220 (Microeconomics and Macroeconomic Outcomes) EC2214 (The Macroeconomic Environment in a Global Context) EC3151 (Economics of Social Policy 2)\n\n\nRecommended Readings\n\n\nMacroeconomics, by Daron Acemoglu, David Laibson, and John A. List\nEconomics For The Common Good, by Jean Tirole\nRisky Business: Why Insurance Markets Fail and What To Do About It, by Amy Finkelstein, Liran Einav, and Raymond Fisman\nThe Entrepreneurial State: Debunking Public VS Private Sector Myths, by Mariana Mazzucato\nThe Price of Inequality, by Joseph Stiglitz\nWhy Most Things Fail, by Paul Ormerod\nSlouching Towards Utopia: An Economic History of the Twentieth Century, by J. Bradford DeLong\nEconomyths: How The Science of Complex System is Transforming Economic Thought, by David Orrell\nA Random Walk Down Wall Street: The Time-Tested Strategy For Successful Investing, by Burton G. Malkiel\nThe Intelligent Investor, by Benjamin Graham\n\n\n\n\n\nMicroeconomics (BSc)\n\nThis covers a series of courses I taught at University College Cork. The content relates to undergraduate microeconomics, and was taught to students studying economics, finance, and commerce. Relevant materials can be made available upon request.\n\nIntroductory Microeconomics\n\nThese courses start by introducing fundamental economic principles at the individual level, focusing on supply, demand, market equilibrium, opportunity costs, and elasticity. The material then evolves to emphasize consumer and producer behaviour under different conditions and within different market contexts.\nThese courses then pivot to consider the role of firms and governments in the microeconomic environment. Of particular interest here is the efficient allocation of resources and leads students to a more nuanced understanding of how policies such as taxation, subsidies, and regulations affect market outcomes.\nIn University College Cork, I have been involved in the following courses which fit this description in different capacities:\nEC1117 (Markets and Governments: An Introduction to Economics) EC1213 (Microeconomic Reasoning and Practice) EC1202 (Economic Reasoning For Business) EC1212 (Economics of Business 1) EC1500 (Ethics and Economic Decision Making in Food Business)\n\n\nRecommended Readings\n\n\nThe Great Economists: How Their Ideas Can Help Us Today, by Linda Yueh.\nHow To Think Like An Economist, by Robbie Mochrie.\nFreakonomics: A Rogue Economist Explores The Hidden Side of Everything, by Steven D. Levitt and Stephen J. Dubner.\nSuperFreakonomics: Global Cooling, Patriotic Prostitutes, and Why Suicide Bombers Should Buy Life Insurance, by Steven D. Levitt and Stephen J. Dubner.\nThink Like A Freak, by Steven D. Levitt and Stephen J. Dubner.\nThe Undercover Economist, by Tim Harford.\nHow To Teach Economics To Your Dog: A Quirky Introduction, by Rebecca Campbell and Anthony McGowan.\nEdible Economics: A Hungry Economist Explains The World, by Ha-Joon Chang.\n\n\n\nIntermediate Microeconomics\n\nThese courses build upon introductory material by focusing on the interactions between producers and consumers within different types of markets. In particular, entrepreneurship, the competitive process and technological change, the determination of the relative prices of goods, and factors of production under various types of market structure are all covered.\nThese courses then pivot in three distinct directions to focus on the government, the firm, and labour market. We consider the role of government in achieving social goals and public policy objectives. Students examine how government actions impact resource allocation, income distribution, and overall welfare. For the firm, we focus on budgets, risk and uncertainty, revenue functions, alongside production and cost analysis. While in labour markets, we emphasize the factors driving labour supply and demand, the acquisition of training and skills, technology and decision making, alongside government intervention in such markets, such as through minimum wages and taxation.\nIn University College Cork, I have been involved in the following courses which fit this description in different capacities:\nEC1121 (Markets, Governments, and The Economics of Social Issues) EC2200 (Economics of Managerial Decision Making) EC3127 (Economics of The Labour Market) EC4211 (Economics of The Labour Market)\n\n\nRecommended Readings\n\n\nThe Great Economists: How Their Ideas Can Help Us Today, by Linda Yueh.\nHow To Think Like An Economist, by Robbie Mochrie.\nFreakonomics: A Rogue Economist Explores The Hidden Side of Everything, by Steven D. Levitt and Stephen J. Dubner.\nSuperFreakonomics: Global Cooling, Patriotic Prostitutes, and Why Suicide Bombers Should Buy Life Insurance, by Steven D. Levitt and Stephen J. Dubner.\nThink Like A Freak, by Steven D. Levitt and Stephen J. Dubner.\nThe Undercover Economist, by Tim Harford.\nHow To Teach Economics To Your Dog: A Quirky Introduction, by Rebecca Campbell and Anthony McGowan.\nEdible Economics: A Hungry Economist Explains The World, by Ha-Joon Chang.\nNudge: Improving Decisions About Health, Wealth, and Happiness, by Richard H. Thaler and Cass R. Sunstein.\nMisbehaving: The Making of Behavioral Economics, by Richard H. Thaler.\nSmall Is Beautiful: A Study of Economics As If People Mattered, by Ernst F. Schumacher\nMicroeconomics by N. Gregory Mankiw and Mark P. Taylor.\nMicroeconomic Foundations I: Choice and Competitive Markets by David M. Kreps.\nMicroeconomic Foundations II: Imperfect Competition, Information, and Strategic Interaction by David M. Kreps.\nChicago Price Theory by Sonia Jaffe, Robert Minton, Casey B. Mulligan, and Kevin M. Murphy.\nMicroeconomic Theory by Andreu Mas-Collel, Michael Whinston, and Jerry Green.\n\n\n\n\nResearch Supervision (BSc, MSc, and PhD)\n\n\n\nSome Background\n\nI thoroughly enjoy supervising research projects, especially those at the MSc and PhD level. The topics I am interested in broadly fall under the umbrella subjects of Urban Studies, Urban Economics, Regional Science, Economic Geography, and Transportation. If the core focus of a given project falls within the remit of any of these subjects, then chances are that I will be interested in supervising it. One thing that I am passionate about is writing, and ensuring that students produce a high-quality written product which is among the top priorities for me when I supervise independent research projects.\nTo help students along in this journey, I have created a writing guide which provides a broad scaffold students can use when learning how to write effectively. You can access this guide here.\nIf you are a student and especially interested in working on a specific topic under my direct supervision, please email me at c [dot] odriscoll [at] rug [dot] nl\n\n\n\nBSc Research Project Supervision\n\nAt the University of Groningen, I am heavily involved in the supervision of BSc theses. Usually, I take two groups of students: one per semester. When I supervise these groups on my own, my theme of choice is Cities.\nI’m drawn to the subject of cities because they illuminate how human potential is concentrated, expressed, and contested in space. For much of history, cities have been foundational to economic growth, innovation, and social change. Their dense networks of people, ideas, and resources create agglomeration effects that not only boost productivity but also shape everyday life and long-term regional prosperity. Cities are not just economic engines—they are complex living systems where geography, economics, planning, and sociology converge, offering a lens into the structures and dynamics that define the modern world.\nWhat fascinates me is this dual nature: cities are sites of opportunity and dynamism, but also of tension and inequality. The very features that make urban areas productive—density, connectivity, diversity—also generate challenges like housing shortages, congestion, environmental degradation, and social fragmentation. As urbanisation accelerates and the spatial distribution of economic activity becomes increasingly uneven, cities expose and amplify regional disparities, while also being on the front lines of global risks such as climate change, public health crises, and economic shocks.\nStudying cities, for me, is a way to understand how spatial processes shape economic and social outcomes, how individual and collective decisions are mediated by place, and how policy can engage with these dynamics to foster more equitable and resilient futures. Cities aren’t just where things happen—they are how things happen.\nWithin this group, I place no hard restrictions on the type of questions students can tackle, so long as those questions are intricately linked to cities. Given my background, I like to stress that the broad subjects students should focus on within this theme include Urban Studies, Urban Economics, Economic Geography, Regional Science, and Transportation\nSometimes, I share group supervision duties. In this context, the theme can change to suit the expertise of the person I am working with. I have listed some of these themes below:\n\nTo Be Added.\nTo Be Added.\n\n\n\n\nMSc Thesis Supervision\n\nAt the University of Groningen, I am heavily involved in the supervision of MSc thesis students in the Economic Geography and Real Estate Studies programme. Much like my philosophy for supervising BSc students, I tend to cast a wide net topic-wise, and encourage any quantitatively-oriented student to reach out if they have a cool idea they would like to explore which falls under the broad remit of Urban Studies, Urban Economics, Economic Geography, Regional Science, and Transportation.\n\n\n\nPhD Thesis Supervision\n\nI have no formal experience supervising PhD students, yet. Watch this space as in the coming months this will change."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Publications and Talks",
    "section": "",
    "text": "Conor O’Driscoll. 2025. “Commuting in Flux: The Roles of Place and Personal Circumstance In Shaping Behavioural Plasticity”.\n\nPowerPoint Slides: ERSA 2025, Athens, Greece\n\nConor O’Driscoll and Milad Abbasiharofteh. 2025. “Roots and Routes: Residential Relocation and Relatedness”.\nConor O’Driscoll and Federica Rossi. 2025. “Residential Relocation Decisions and Destinations: The Role of Working From Home”.\n\nPowerPoint Slides: ERSA 2025, Athens, Greece\n\nConor O’Driscoll and Ana Maria Silva. 2025. “Working From Home and Labour Market Outcomes: The Case of Earnings and Hours Worked”.\nConor O’Driscoll and Luise Koeppen. 2025. “Subnational Institutional Corruption and Political Discontent”.\nConor O’Driscoll. 2025. “Navigating Change: Residential Relocation, Travel Behaviours, and Built Environments”. Major Revisions in Papers in Regional Science.\n\nPowerPoint Slides: RSAI BIS 2024, Bristol, UK"
  },
  {
    "objectID": "research.html#select-ongoing-projects",
    "href": "research.html#select-ongoing-projects",
    "title": "Publications and Talks",
    "section": "",
    "text": "Conor O’Driscoll. 2025. “Commuting in Flux: The Roles of Place and Personal Circumstance In Shaping Behavioural Plasticity”.\n\nPowerPoint Slides: ERSA 2025, Athens, Greece\n\nConor O’Driscoll and Milad Abbasiharofteh. 2025. “Roots and Routes: Residential Relocation and Relatedness”.\nConor O’Driscoll and Federica Rossi. 2025. “Residential Relocation Decisions and Destinations: The Role of Working From Home”.\n\nPowerPoint Slides: ERSA 2025, Athens, Greece\n\nConor O’Driscoll and Ana Maria Silva. 2025. “Working From Home and Labour Market Outcomes: The Case of Earnings and Hours Worked”.\nConor O’Driscoll and Luise Koeppen. 2025. “Subnational Institutional Corruption and Political Discontent”.\nConor O’Driscoll. 2025. “Navigating Change: Residential Relocation, Travel Behaviours, and Built Environments”. Major Revisions in Papers in Regional Science.\n\nPowerPoint Slides: RSAI BIS 2024, Bristol, UK"
  },
  {
    "objectID": "research.html#published-research-papers",
    "href": "research.html#published-research-papers",
    "title": "Publications and Talks",
    "section": "Published Research Papers",
    "text": "Published Research Papers\n\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy; Josh O’Driscoll. 2025. “Travel Behaviours and Built Environments on School-Runs”. Regional Science Policy and Practice, 17(1), pp.1-14. doi: 10.1016/j.rspp.2024.100153.\nKevin Credit and Conor O’Driscoll. 2024. “Assessing Modal Tradeoffs and Associated Built Environment Characteristics Using a Cost-Distance Framework”. Journal of Transport Geography, 117, pp.1-19. doi: 10.1016/j.jtrangeo.2024.103870.\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy. 2024. “The relationships between socio-demographics, residential environments, travel considerations, and commute mode choice in Ireland”. Regional Studies, 58(3), pp.1-18. doi: 10.1080/00343404.2023.2199779.\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy. 2023. “Land-Use Mix in Ireland: Implications for Sustainable Development”. Journal of Maps, 19(1), pp.1-7. doi: 10.1080/17445647.2023.2214165.\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy. 2023. “Land-Use Mixing in Irish Cities: Implications for Sustainable Development”. Land Use Policy, 128(5), pp.1-7. doi: 10.1016/j.landusepol.2023.106615.\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy. 2022. “Retail Sprawl and CO2 Emissions: Retail Centres in Irish Cities”. Journal of Transport Geography, 102(6), pp.1-12. doi: 10.1016/j.jtrangeo.2022.103376."
  },
  {
    "objectID": "research.html#public-outreach-research-dissemination",
    "href": "research.html#public-outreach-research-dissemination",
    "title": "Publications and Talks",
    "section": "Public Outreach / Research Dissemination",
    "text": "Public Outreach / Research Dissemination\n\nConor O’Driscoll. 2024. “The Cost of Morning Commutes: The Case of Kildare”. Kildare FM.\nConor O’Driscoll and Kevin Credit. 2024. “Here’s the real cost of your morning rush hour commute in Dublin”. RTE Brainstorm.\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy. 2023. “How the relationship between socio- demographics, residential environments and travel influence commuter choices”. Regional Studies Blog.\nConor O’Driscoll. 2023. “Retail Centre Locations in Cork: The Case of Carrigtwohill”. RTE Prime Time.\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy. 2022. “Planning For Sustainability: Future Retail Centre Locations”. The Boolean, 6(8), pp.27-32.\nConor O’Driscoll; Frank Crowley; Justin Doran; Nóirín McCarthy. 2022. “The Links Between Where We Live and How We Commute”. RTE Brainstorm.\nJane Bourke; Josh O’Driscoll; Conor O’Driscoll. 2022. “Does fear of failure hamper Irish business innovation?”. RTE Brainstorm.\nConor O’Driscoll. 2021. “Why out of town retail parks don’t make sense in a climate crisis”. RTE Brainstorm.\nConor O’Driscoll. 2021. “Shopping Malls, GHG Emissions and The Role of Policymakers in”Green” Transportation Infrastructure in Ireland”. Regional Studies Association: Student Summer Series."
  },
  {
    "objectID": "research.html#talks",
    "href": "research.html#talks",
    "title": "Publications and Talks",
    "section": "Talks",
    "text": "Talks\n\nConor O’Driscoll. 2025. “Mobility and Economic Geography”.\n\nAn invited early-career keynote speech to be delivered at the Regional Science Association International: British and Irish Section. The conference was held in Cork, Ireland.\n\nConor O’Driscoll. 2025. “Stuck in the Mud? Geographical Immobility Across The UK”.\n\nPresentation of an ongoing research project at the Regional Science Association International: British and Irish Section. The conference was held in Cork, Ireland.\n\nConor O’Driscoll. 2024. Navigating Change: The PhD Journey and Life After.\n\nAn invited workshop by colleagues at the Spatial and Regional Economic Research Centre, University College Cork. Topics covered in the workshop include: Navigating the PhD Journey, The Research Process, Publishing Research, and The Academic Job Market.\n\nConor O’Driscoll. 2024. Land-Use Patterns and Commuting in Cork.\n\nThis invited workshop, hosted by the Regional Studies Association (Irish Section), covered the topic of pressing transportation issues in Ireland. At this workshop, I presented ongoing research about commuting flows in the Cork Metropolitan Area, while other notable speakers included Dr. Kevin Credit of Maynooth University and Prof. Hannah Daly of University College Cork.\n\nConor O’Driscoll. 2024. Writing and Research in University.\n\nThis invited talk was hosted for undergraduate students about to undertake the first research project of their academic journeys. The purpose of this talk was to introduce them to writing conventions, techniques, and illustrate expectations surrounding what is “expected” in the writings of a university student."
  },
  {
    "objectID": "posts/commute_costs.html",
    "href": "posts/commute_costs.html",
    "title": "What is the cost of commuting?",
    "section": "",
    "text": "It’s well known that where you live influences how you travel. A recent study, co-authored with Dr. Kevin Credit takes a different approach by exploring how where you live impacts the cost of travelling. More specifically, we look at how different types of built environments shape the costs of using particulary modes of transport, and the costs of travelling along specific routes, when commuting in the Dublin metropolitan area.\n\nUnderstanding Travel Costs\nAt the heart of our study is the concept of mobility costs—a way of capturing how much effort, time, and inconvenience it takes to commute using different modes of transport. These costs aren’t just financial; they reflect how infrastructure, congestion, and land-use patterns shape the real-world effectiveness of getting from A to B. Rather than looking only at which transport modes people choose, we focus on how cost-effective those modes are in different local environments. Using a “cost-distance” approach, we estimate the relative efficiency of car travel, walking, cycling, and public transport across the Dublin region. This allows us to uncover how built environments influence travel indirectly, by making certain modes more or less viable in different areas.\nDrawing on 2016 Census data and sources like Google Maps, OpenStreetMap, and the Irish Revenue Commissioners, we link commuter flows to detailed transport networks. We then use random forest models, a type of machine learning, to uncover how local environments shape mobility costs—often in complex, non-linear ways.\n\n\nWhat we found\nActive travel (walking and cycling) is most cost-effective in central Dublin and denser, walkable areas—but this benefit fades in overly dense or congested areas. We link this to the fact that these characteristics, while initially beneficial, can eventually lead to overcrowded streets, longer wait times at crossings, and more frequent stops. In these settings, travelling on foot or by bike may become stressful, when compared to other modes.\nSurprisingly, public transport is also quite inefficient in very dense areas. One might expect that higher density would support better service, shorter wait times, and greater usage. However, we suspect this result emerges because, in Ireland, road space is shared between cars and buses. The result? Cars and buses get stuck in the same traffic, making the trade-off between cars and public transport one which revolves around convenience and reliability—trade-offs cars win every time given the lack of countervailing measures (e.g., congestion pricing) in Irish city centres.\nThese patterns highlight how urban form and infrastructure design shape the real cost of commuting—not just in money, but in time, effort, and convenience.\n\n\nWhy this matters\nIf cities want to encourage sustainable travel, they need to reduce the relative cost of walking, cycling, and public transport. That means investing in segregated infrastructure, like bus and bike lanes that bypass congestion. But it also means designing coherent, connected transport networks, and thus directly influencing the viability of different transport modes across the urban-rural continuum.\nOne key observation we make is that Dublin’s public transport and cycling networks may be lagging behind those of global cities. For public transport, this observation stems from the lack of segregated transport infrastructure, while for active transport, it stems from the fragmentation of networks.\nProjects like BusConnects are steps in the right direction. But unless they’re supported by smart land-use planning that curbs sprawl, their impact will be limited. Simply put: we can’t build our way out of car dependence without also re-shaping the environments people move through.\nFor policymakers and urban designers, the message is clear: making sustainable travel easier isn’t just about offering alternatives: it’s about making those alternatives cost-effective, reliable, and competitive with the car.\nFor the full technical details, please refer to the full paper."
  },
  {
    "objectID": "posts/data_vis.html",
    "href": "posts/data_vis.html",
    "title": "Always visualise your data: Simpsons Paradox in action",
    "section": "",
    "text": "If you’ve ever opened a dataset and jumped straight into statistical testing, you’re not alone. It’s tempting to rush toward a result — an effect, a relationship, a difference — and get to work writing it up. But what if the “result” you find hides a deeper contradiction? What if the truth is visible in your data, but only if you look at it the right way?\nThis is where data visualization comes in. Visualization is how we make our data legible not just to others, but to ourselves. Indeed, I would make the case that you cannot fully understand what is going on in your data without some form of data visualisation as it helps us detect patterns, check assumptions, and avoid being misled.\nTo illustrate this, let’s explore one of the most famous cases where misleading aggregate data can lead to erroneous conclusions: Simpson’s Paradox, using the classic UC Berkeley admissions dataset from 1973.\n\nSetting The Scene\nImagine that you’re interested in studying gender bias in university admissions. You obtain real administrative data from UC Berkeley’s graduate programs from 1973 and start with what seems like a straightforward question:\nWere men more likely to be admitted than women?\nYou begin by exploring what type of data you have available in your dataset.\nIn this post, we will use the UCBAdmissions dataset: A well-known built-in R dataset derived from real administrative records of graduate admissions at UC Berkeley in 1973.\n\n#The relevant packages have been loaded elsewhere\n\n#Load the data\ndata(UCBAdmissions)\nucb_df &lt;- as.data.frame(UCBAdmissions)\n\n#What are the variable names?\nnames(ucb_df)\n\n[1] \"Admit\"  \"Gender\" \"Dept\"   \"Freq\"  \n\n#A broad overview of the structure these variables take\nglimpse(ucb_df)\n\nRows: 24\nColumns: 4\n$ Admit  &lt;fct&gt; Admitted, Rejected, Admitted, Rejected, Admitted, Rejected, Adm…\n$ Gender &lt;fct&gt; Male, Male, Female, Female, Male, Male, Female, Female, Male, M…\n$ Dept   &lt;fct&gt; A, A, A, A, B, B, B, B, C, C, C, C, D, D, D, D, E, E, E, E, F, …\n$ Freq   &lt;dbl&gt; 512, 313, 89, 19, 353, 207, 17, 8, 120, 205, 202, 391, 138, 279…\n\n\nOk. These commands already tells us a lot about the structure of the dataset. There are four variables (columns) and 24 unique data points (rows). More specifically, we can see that it counts the number of applications for six departments by admissions status and sex. To really ensure that you understand the structure of this dataset, try answering the following questions:\n\n\nWhat type of variable is Admit? RatioIntervalBinaryNominalOrdinal\nWhat type of variable is Gender? RatioIntervalNominalOrdinal\nWhat type of variable is Freq? RatioIntervalBinaryNominalOrdinal\nWhat type of variable is Dept? RatioIntervalBinaryNominalOrdinal\nWhat type of variable is labelled as fct? BinaryNominalOrdinalAll of these\nWhat type of variable is labelled as dbl? IntervalRatioBoth of these\n\n\n\n\nAggregate Trends: A Broad Overview\nNow that we know how our dataset is structured and broadly what the variables look like, we can revisit our main research question: Were men more likely to be admitted than women?\nHow might we begin answering such a question? A logical first step might be to summarize overall admission rates by sex:\n\n#Calculate overall admission rates by gender\noverall_admit &lt;- ucb_df %&gt;%\n  group_by(Gender, Admit) %&gt;%\n  summarise(Freq = sum(Freq)) %&gt;%\n  tidyr::pivot_wider(names_from = Admit, \n                     values_from = Freq) %&gt;%\n  mutate(Total = Admitted + Rejected,\n         AdmitRate = Admitted / Total) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'Gender'. You can override using the\n`.groups` argument.\n\n#Display the table\nprint(overall_admit)\n\n# A tibble: 2 × 5\n  Gender Admitted Rejected Total AdmitRate\n  &lt;fct&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 Male       1198     1493  2691     0.445\n2 Female      557     1278  1835     0.304\n\n\nTo ensure that you understand what this code is doing, try answering the following questions:\n\n\nTrue or False: Grouping by Gender and Admit allows us to generate seperate counts of admissions and rejections by Gender and Department. TRUEFALSE\nTrue or False: Grouping by Admit is unnecessary to generate the values used to compute AdmitRate. TRUEFALSE\nIf we wanted to make this table more professional in its presentation, which of the following packages might we use? ggplot2tidyversekableExtrastargazer\nWhich type of table does this example most closely resemble? summary statistics tablecrosstablefrequency table\n\n\nAt first glance, the results seem clear: men are more likely to be admitted to graduate school in UC Berkeley than woman.\n\n\nWhich column do we use to come to this conclusion? GenderAdmittedRejectedTotalAdmitRate\n\n\n\n\nDigging A Bit Deeper: Department-Specific Heterogeneity?\nYou might stop here and think your work is done. But this only tells us what is going on in the aggregate. Unless you are a macroeconomist, you should know better than to trust aggregate data; something interesting probably lies beneath the surface. So, with this in mind, we shall dig a bit deeper.\nLet’s start by breaking this down by department. The data includes six departments, labeled A–F. What happens when we examine admission rates within departments?\n\ndept_admit &lt;- ucb_df %&gt;%\n  group_by(Dept, Gender, Admit) %&gt;%\n  summarise(Freq = sum(Freq)) %&gt;%\n  tidyr::pivot_wider(names_from = Admit, \n                     values_from = Freq) %&gt;%\n  mutate(Total = Admitted + Rejected,\n         AdmitRate = Admitted / Total)\n\n`summarise()` has grouped output by 'Dept', 'Gender'. You can override using\nthe `.groups` argument.\n\nprint(dept_admit)\n\n# A tibble: 12 × 6\n# Groups:   Dept, Gender [12]\n   Dept  Gender Admitted Rejected Total AdmitRate\n   &lt;fct&gt; &lt;fct&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 A     Male        512      313   825    0.621 \n 2 A     Female       89       19   108    0.824 \n 3 B     Male        353      207   560    0.630 \n 4 B     Female       17        8    25    0.68  \n 5 C     Male        120      205   325    0.369 \n 6 C     Female      202      391   593    0.341 \n 7 D     Male        138      279   417    0.331 \n 8 D     Female      131      244   375    0.349 \n 9 E     Male         53      138   191    0.277 \n10 E     Female       94      299   393    0.239 \n11 F     Male         22      351   373    0.0590\n12 F     Female       24      317   341    0.0704\n\n\n\n\nOne of the following statements best describes the core difference between dept_admit and overall_admit. Pick the most appropriate:\n\n overall_admit counts admissions and rejections by sex; dept_admit further breaks this down by sex overall_admit gives us aggregate trends while dept_admit provides more disaggregated insights dept_admit fails to account for admission status while overall_admit does\n\n\n\nNow the story flips: in most departments, women have higher admission rates than men. So how can the overall numbers suggest the opposite? This reversal is a textbook example of Simpson’s Paradox - a phenomenon where a trend appears in different groups but reverses when the groups are combined.\nIn this case, women were more likely to apply to departments with lower overall admission rates (e.g., departments C, D, E, F), while men applied more to departments with higher admission rates (departments A and B). The aggregate numbers hide this because they mix different denominators across departments.\nThis illustrates a broader lesson: data summaries without disaggregation can obscure the underlying structure of your data. And without visualization, this kind of paradox is hard to detect.\nLet’s visualize the department-level admission rates by gender.\n\nggplot(dept_admit, aes(x = Dept, \n                       y = AdmitRate, \n                       fill = Gender)) +\n  geom_col(position = \"dodge\") +\n  labs(title = \"Admission Rates by Gender and Department (UC Berkeley, 1973)\",\n       y = \"Admission Rate\", \n       x = \"Department\") +\n  scale_fill_manual(values = c(\"Male\" = \"#377eb8\", \n                               \"Female\" = \"#e41a1c\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nWhich of the following charts best describes the chart displayed above? histogrampie chartbar chartscatterplotstem-and-leaf diagram\nWhat do the letters x and y refer to, in statistical terms?\n\n X refers to an independent variable; Y refers to a dependent variable X refers to an dependent variable; Y refers to a independent variable X refers to an endogenous variable; Y refers to a exogenous variable X refers to the variable which determines the value of Y Y refers to the variable which determines the value of X\n\nWhich of the following might best describe why we have put AdmitRate as the Y variable in this chart?\n\n Because admission rates determine which department an applicant chooses Because we want to compare how likely applicants are to be admitted across departments and genders Because AdmitRate is a control variable in the admissions process Because AdmitRate belongs on the Y-axis for statistical validity\n\n\n\nThis plot shows that in nearly all departments, women had similar or higher admission rates than men. The illusion of bias in the aggregate comes from differences in application patterns, not unfair decisions within departments. To confirm this, let’s also show how department choice varied by gender.\n\napplicants &lt;- ucb_df %&gt;%\n  group_by(Dept, Gender) %&gt;%\n  summarise(Applicants = sum(Freq))\n\n`summarise()` has grouped output by 'Dept'. You can override using the\n`.groups` argument.\n\nggplot(applicants, aes(x = Dept, \n                       y = Applicants, \n                       fill = Gender)) +\n  geom_col(position = \"dodge\") +\n  labs(title = \"...\",\n       y = \"...\", \n       x = \"Department\") +\n  scale_fill_manual(values = c(\"Male\" = \"#377eb8\", \n                               \"Female\" = \"#e41a1c\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis second chart reveals that men were more likely to apply to departments A and B, which had higher acceptance rates, while women applied more often to departments C through F, where competition was steeper.\n\n\nWhat is the core difference between the two charts presented above?\n\n The first displays raw admission counts, while the second displays admission rates The first displays admission rates, while the second displays raw admission counts the first chart is inappropriate and brings no added value to the analysis, while the second chart is highly valuable the second chart is inappropriate and brings no added value to the analysis, while the first chart is highly valuable there is no core difference between the two charts; this is a trick question\n\n\n\n\n\nWrapping Up\nThis example is more than a historical curiosity—it’s a powerful reminder of what can go wrong when we skip visual exploration. Without breaking down the data into meaningful subgroups or visualizing it, we risk drawing misleading conclusions from aggregated numbers—a mistake that can easily obscure important patterns or biases hidden within the data. Here are a few key takeaways:\n\nNever Rely on Aggregates Alone Always ask: What groups might I be collapsing? Can different subgroups tell different stories?\nUse the Right Visualization for the Question Tables are great for precision, but bar plots, dot plots, and faceted graphics help reveal structure. In this case, side-by-side bar charts made the paradox visible in seconds.\nVisuals Help You Understand Your Own Data Good graphics aren’t just for presentations. They’re how you, as a researcher or analyst, come to understand the texture of the data you’re working with.\nTabulation Has Added Value When It Reveals Structure A well-designed cross-tab or grouped summary tells you what’s driving a result. Don’t just count things—count them strategically.\n\n\n\nHungry For More?\nFor more information on the exact data used in this post, check out the full paper here. Alternatively, type help(UCBAdmissions) into the R console if you wish to replicate or extend the analyses conducted here."
  },
  {
    "objectID": "posts/welcome.html",
    "href": "posts/welcome.html",
    "title": "Welcome to my website!",
    "section": "",
    "text": "Welcome to my website! My name is Conor O’Driscoll and I am an Assistant Professor in Economic Geography within the University of Groningen’s Faculty of Spatial Sciences.\nThis website will serve as a repository for research-related items, teaching materials, and other academic things people may find interesting. Any material borrowed from this website and used in the public domain should be referenced appropriately, but otherwise, I hope you enjoy it and find use in some of it. Below, I provide an outline of what you can expect from, and find on, this website."
  },
  {
    "objectID": "posts/welcome.html#miscellaneous",
    "href": "posts/welcome.html#miscellaneous",
    "title": "Welcome to my website!",
    "section": "Miscellaneous",
    "text": "Miscellaneous\nOther elements of this site contain a copy of my cv in pdf and raw html form as well as a News and Musings section in which you can find personal and professional updates, alongside blog posts related to my research and teaching activities.\nHappy reading and looking forward to seeing how this project evolves and grows! Conor"
  },
  {
    "objectID": "posts/diff_data_1.html",
    "href": "posts/diff_data_1.html",
    "title": "Different Types of Data: Part 1",
    "section": "",
    "text": "What Is Data? A Continuation\nData describe the universe we wish to study. There are no ends to the universes which can be studied, and therefore the universes represented by data.\nData is everywhere. From the number of emails in your inbox to city traffic counts, data help us make sense of the world. But not all data are the same. Understanding the types of data, where they come from, and how they’re documented is essential for using them effectively.\n\n\nSources of Data: Internal vs. External\nAt the most basic level, we distinguish between data that already exist in some form, from data that we propose to collect ourselves in the course of our research. Data are said to be internal when they are available in some form through existing records/files of an institution undertaking the study. That is, the data are already available to you internally and thus you do not have to collect it. With this in mind, a key characteristic of internal data is that the researcher knows an awful lot about how the data was collected and what they are measuring. Examples include sales figures, employee records, or website analytics. These data are often easier to access and tailor-made for your (organisation’s) specific needs.\nData are said to be external when they are obtained from an external entity/organisation. That is, the data are coming from outside sources. In these situations, many important characteristics about the data (i.e., how they were collected and measured) may not be known. Examples include census data, market reports, or climate records from government agencies. External data can enrich internal analysis by providing context or allowing comparisons across organizations or regions.\nBoth internal and external data can be valuable, but they may differ in format, quality, and availability. Understanding the source helps determine how much you can trust it and how it can be used. Indeed, it is not unusual to derive results in a statistical analysis that cannot be explained without detailed knowledge of the data source.\nBecause internal data is often tailor-made to suit a specific objective, many institutions, researchers, and organisations collect what are otherwise very similar data but are both measured and used in different ways. One obvious example here concerns geographical statistics (i.e., urbanisation) across countries. Many countries have different definitions for cities and urban areas, thus making measurements of urbanisation very different. Yet most are interested in measuring urbanisation in some sense. The differing objectives and approach to collecting such data raises immediate issues for researchers and organisations interested in, say, comparing urbanisation levels across countries. At times, statisticians are called upon to make comparisions across countries, in this case, for which data collection procedures are different, data accurracy differs, and even data definitions differ - hence the considerable resources dedicated by organisations like the UN to gather and integrate such disparate data sources. With this in mind, caution should always be exercised in the use of external data.\n\nTo test your understanding of the different types of data, try to answer the following questions:\n\nYou work in the Sales Department of Albert Heijn’s corporate offices and wish to study the profit margins of the in-store bakeries across the Netherlands. The data you are using is … InternalExternalNeitherA Mix of Both\nYou work for the University of Groningen and wish to use CBS microdata to study wage distributions across different Dutch municipalities. The data you are using is … InternalExternalNeitherA Mix of Both\nYou want to study how your personal expenditures on groceries have changed over the past twelve months. To this effect, you have kept all of your receipts and wish to conduct some statistical analysis. The data you are using is … InternalExternalNeitherA Mix of Both\n\n\n\n\nPrimary Versus Secondary Data\nAnother useful distinction is between primary and secondary data. Primary data are data collected firsthand by a researcher, organization, or system for a specific purpose. They come directly from the original source. Some examples include: survey responses, experiments, observations, sales transactions. Secondary data are data that were collected by someone else, often for a different purpose, and are later reused for analysis. Some examples include: census statistics, published research datasets, government or NGO reports.\nInternal data are always primary because they are collected firsthand within the organization for a specific purpose. The advantage of primary data is that you have control over the process, measurement, and definitions. The downside is that collecting primary data can be costly and time-consuming.\nSecondary data, by contrast, are collected by someone else, often for a different purpose, and are reused for your analysis. Examples include government statistics, academic datasets, or industry reports. Secondary data are usually easier and cheaper to access, but you must critically evaluate whether they are appropriate, reliable, and up-to-date for your questions.\nWhen using external data, it is important to always important to get as close to the primary source as possible. The difficulty with secondary sources is that they may contain data that has been altered by recording or editing errors, selective data omission, rounding, aggregation, questionable merging of datasets from different sources, or various ad hoc corrections. For example, never use an encyclopedia to get a list of the 10 largest cities in Europe; use the data collected by Eurostat - the statistics agency dedicated to collecting consistent socio-economic statistics across European countries.\nOften, good research combines both: using secondary data for context or historical perspective, and collecting primary data to answer specific, current questions.\n\nTo test your understanding of the different types of data, try to answer the following questions:\n\nYou wish to study sentiments of stock markets before, during, and after financial crises. You reason that reports from leading newspapers of the time offer reasonable approximations of how society felt about financial markets. So you read through these articles and generate an index from the information provided. The type of data you are using is … PrimarySecondaryNeitherA Mix of Both\nYou are studying student housing affordability in Barcelona, Spain, and conduct a survey at the Univeristy of Barcelona which asks questions concerning things like income, rental prices, and living arrangements. The type of data you are using is … PrimarySecondaryNeitherA Mix of Both\nYou are studying the evolution of property prices in England and Wales since the Great Recession and use the property price index developed in Ahlfeldt, Carozzi, and Makovsky (2023) to do this. The data you are using is PrimarySecondaryNeitherA Mix of Both\nYou are studying labour market outcomes across the United States and use U.S Census data to do so. The data you are using is PrimarySecondaryNeitherA Mix of Both.\n\n\n\n\nMetadata: Data about Data\nFinally, any serious discussion of data types is incomplete without mentioning metadata.\nMetadata are data about data. They describe how, when, where, and by whom the data were collected, as well as definitions, units, and any limitations. For example, a dataset of school test scores might include metadata detailing the grade level, the subjects tested, the testing dates, and how missing values were handled.\nMetadata are essential for interpreting and reusing data correctly. Without metadata, even well-collected data can be confusing or misleading. Think of metadata as the instruction manual for your dataset — it tells you what the numbers or categories really mean and how to use them responsibly. They are usually presented in document (i.e., pdf) or spreadsheet (i.e., excel) format, and if they do not come directly with the data themselves, will usually be readily available from whatever source they come from.\nAny dataset worth its salt contains some form of metadata. Admittedly, some will be better than others, but nearly all modern datasets have something to work from.\n\nConsidering the characteristics of metadata, answer the following question:\n\nMetadata are readily available with primary data.\n\n No, not unless you make metadata to accompany whatever primary data you have collected. Yes, any dataset worth its salt contains some form of metadata. Therefore, every dataset will come with some No. It is impossible to have metadata for primary data since you must collect the data yourself\n\n\n\nData can be distinguished in several ways. Source (internal or external) and collection method (primary or secondary) are two ways which we have explored today. But there are others, namely by nature, something that will be explored in my next post.\nAlongside the data itself, metadata provides essential documentation about its structure, meaning, and quality. Recognizing these distinctions helps you select the right data, apply it effectively, and interpret it responsibly; because data is powerful only when we understand where it comes from, how it was collected, and what it truly represents.\n\n\nBibliography\n\nStatistics: A Very Short Introduction, by David J. Hand\nElementary Statistics For Geographers by James Burt, Gerald Barber, and David Rigby"
  },
  {
    "objectID": "posts/diff_data_2.html",
    "href": "posts/diff_data_2.html",
    "title": "Different Types of Data: Part 2",
    "section": "",
    "text": "Different Types of Data Collection\nWhen we talk about “data,” we’re really talking about many different things at once: how the information was collected, how it is structured, and how it can be measured. Understanding these distinctions is the first step toward using data responsibly and effectively.\nData can be collected in many different ways. Surveys and questionnaires ask people directly about their opinions, behaviors, or experiences. Experiments create controlled situations designed to test specific hypotheses. Observations involve recording what you see in the world without interfering. Administrative records capture information as part of routine operations, like hospital admissions or school enrollments. Increasingly, digital traces—such as website clicks or social media activity—provide vast new sources of information.\nEach of these methods has strengths and limitations: surveys capture personal perspectives but depend on honest responses, administrative data is often large and reliable but may miss key details, and experiments are powerful for identifying cause and effect but can be costly or artificial. The way data is collected shapes what it can and cannot tell you.\n\n\nThe Structure of a Dataset\nBroadly speaking, it is convenient to regard data as having two aspects: one aspect covers the objects we wish to study (e.g., schoolchildren), the other covers the characteristics of those objects (e.g., test scores). In statistics, it is common to call these characteristics variables, with each object having a value for every variable under study.\nIn any one study, we might be interested in multiple kinds of objects. we might want to understand and make statements not only about schoolchildren, but also about the schools they attend, the neighbourhoods they live in, the quality of teachers within their school etc. Moreover, we will typically not be interested in any single variable, but rather the relationships between different variables. We may even be interested in seeing how these relationships differ across different types of objects (e.g., boys and girls).\nOnce collected, data is usually organized into a dataset. At its simplest, a dataset is a table in which the rows represent cases (also called observations or units) and the columns represent variables. Cases might be individuals, households, companies, cities, or even single transactions. Variables describe characteristics of those cases, such as age, income, location, or test scores. For example, in a dataset on students, each row might represent a student, while the columns record their gender, age, hours studied, and exam results. Thinking in terms of cases and variables is fundamental because it frames how we analyze data.\n\nNow seems like a good moment to stop and test yourself to ensure that you truly understand what you are reading. Indicate whether each of the statements below is TRUE or FALSE.\n\nIn a typical dataset, columns represent different characteristics of the objects being studied while rows represent unique objects. TRUEFALSE\nCases typically represent what we are studying while variables typically represent who or what we are studying. TRUEFALSE\nIn a dataset tracking the commuting preferences of individuals in Groningen, some relevant variables might include the mode of transport they use, their age, and their gender, while cases might capture different individuals at one (or multiple) points in time. TRUEFALSE\nIn a dataset tracking the commuting preferences of individuals in Groningen, some relevant cases might include the mode of transport they use, their age, and their gender, while variables might capture different individuals at one (or multiple) points in time. TRUEFALSE\n\n\n\n\nQualitative and Quantitative Data\nNot all variables look the same, and this leads us to a key distinction between qualitative and quantitative data. Quantitative data is measured with numbers, such as income, exam scores, or height. Some of these numbers are discrete, meaning they can only take on whole-number values—like the number of children in a household, or the number of books someone has read this month. Others are continuous, meaning they can take on any value within a range, like height, income, or time spent commuting.\nThis distinction matters because it affects how we summarize and analyze the data. For example, with discrete variables, counts and frequencies are often natural summaries, while continuous variables often require measures like averages, ranges, or percentiles.\nQualitative data, on the other hand, refers to categories or descriptions, such as marital status, eye color, or whether someone prefers tea or coffee. This distinction is important because it determines what kinds of analysis are appropriate. You can calculate averages and percentages for quantitative variables, but those operations make little sense for qualitative data. For qualitative variables, frequencies or proportions are often more useful.\nAlthough qualitative data is not inherently numerical, in practice we often assign numbers to categories so that we can analyze them statistically. For example, marital status might be coded as 1 = single, 2 = married, 3 = divorced. Similarly, survey responses like “strongly disagree” to “strongly agree” might be assigned values from 1 to 5. These numbers don’t turn the data into true quantities — they are simply labels that make the data easier to store, summarize, and compare. But the meaning of the numbers depends entirely on the type of variable we are working with, which brings us to the standard classification of data types: nominal, ordinal, interval, and ratio.\n\nBut before we get to that, why not stop and test yourself to ensure that you truly understand what you are reading? Indicate whether each of the statements below is TRUE or FALSE.\n\nThe mode of transport people use to travel to work is a quantitative variable. TRUEFALSE\nThe typical house/apartment number in a regular neighbourhood is a continuous variable. TRUEFALSE\nPost Codes are discrete quantitative variables. TRUEFALSE\nPost Codes are qualitative variables. TRUEFALSE\nTyre pressure is a continuous variable. TRUEFALSE\n\n\n\n\nData Types: Nominal, Ordinal, Interval, Ratio\nNominal data consists of categories without any natural order, such as blood type or favorite fruit. Ordinal data adds an order to the categories, but the spacing between them is not consistent. For example, a satisfaction scale from “poor” to “excellent.” Interval data is numeric and has meaningful spacing between values, but lacks a true zero point. We say something lacks a “true zero” when a value of 0 does not indicate absence of said variable, such as a temperture reading of 0 degrees celcius - you would never say that this means there is no temperature. Ratio data includes all the properties of interval data, but with a true zero, such as height, distance, or income. This last type allows for meaningful ratio comparisons, like saying someone who earns £40,000 makes twice as much as someone earning £20,000, something not possible with interval data, or, more precisely, something not possible when the data lacks a true zero.\n\n\n\n\n\n\nNote\n\n\n\nRatio and interval scales both measure quantities, but there is a key difference: the zero point. Interval scales, like temperature in Celsius or Fahrenheit, have an arbitrary zero — 0°C does not mean “no heat” — so while we can measure differences, we cannot meaningfully say one value is twice another. Ratio scales, like weight or height, have a true zero, which represents a complete absence of the quantity. This absolute zero allows us to make multiplicative comparisons: an object weighing 10 kg is meaningfully twice as heavy as one weighing 5 kg. In short, a true zero provides a fixed anchor that makes ratios and proportional statements meaningful, whereas an arbitrary zero allows only for comparisons of differences.\nAdmittedly, while it is important to understand the theoretical differences between interval and ratio data, this distinction rarely comes into play in practice.\n\n\nThese distinctions may sound abstract, but they matter a great deal in practice. The type of data determines which statistical methods are valid. You can calculate averages for ratio or interval data, but not for nominal data. You can rank ordinal data, but you cannot assume the differences between ranks are equal. Confusing these categories can lead to misleading results. Equally, ignoring how data was collected or structured can mean placing trust in biased or incomplete information.\n\nBefore moving further, try to correctly answer the following questions by selecting the most appropriate data type for each scenario.\n\nWhat type of data is “Blood type (A, B, AB, O)”? ordinalnominalintervalratio\nWhat type of data is “Customer satisfaction rating on a 1–5 scale”? ordinalnominalintervalratio\nWhat type of data is “Temperature in Celsius”? ordinalnominalintervalratio\nWhat type of data is “Annual income in dollars”? ordinalnominalintervalratio\nWhat type of data is “Ranking of students by exam score (1st, 2nd, 3rd, etc.)”? nominalordinalintervalratio\nWhat type of data is “Number of pets someone owns”? ordinalnominalintervalratio\nWhat type of data is “Cuisine preference ranking (e.g., Italian, Mexican, Japanese)”? nominalordinalintervalratio\nWhat type of data is “IQ score”? ordinalnominalintervalratio\nWhat type of data is “Clothing size (S, M, L, XL)”? nominalordinalintervalratio\nWhat type of data is “Distance run in kilometers”? ordinalnominalintervalratio\n\n\nIn short, data is never just data. Its source, structure, and type all shape what we can learn from it. By paying attention to how data is collected, how it is organized, and what kind of information it contains, we can ask better questions, avoid common mistakes, and make stronger, more reliable conclusions."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Conor O’Driscoll",
    "section": "",
    "text": "twitter\n  \n  \n    \n     linkedin\n  \n  \n    \n     google scholar\n  \n  \n    \n     university webpage\n  \n  \n    \n     github\n  \n\n  \n  \nI am an Assistant Professor in Economic Geography at the University of Groningen’s Faculty of Spatial Sciences. I recieved my PhD (Economics) from University College Cork, Ireland, where I was based in the Spatial and Regional Economic Research Centre (SRERC) between 2020-2023.\nI study how location shapes economic and social outcomes for individuals, focusing on the factors driving location decisions and the dynamic relationship between geography, mobility, and economic opportunity. I do quantitative research in Economic Geography, Regional Science, and Transportation Studies. In 2023, I won the Postgraduate Researcher of The Year (2021-2022) at the University College Cork College of Business and Law.\nI teach courses in Introductory and Intermediate Statistics, Quantitative Research Methods, and Economic Geography. I supervise Bachelor Theses in our Human Geography and Planning programme, as well as Master Theses in our Economic Geography and Real Estate Studies programmes. I am the Chief Organiser of the Research Clinic series hosted by the Department of Economic Geography and I serve on the Faculty Council in the Faculty of Spatial Sciences\nIn my free time, I like to run, play chess, cook, and read. I am a big Track and Field fan, but also enjoy watching football (soccer). I have had the honour of representing the Republic of Ireland 4 times in competitive athletics and have won numerous national titles across four track events.\n\n\n\nThanks for checking out my web site! If you have questions or wish to collaborate, you can reach me at c [dot] odriscoll [at] rug [dot] nl"
  },
  {
    "objectID": "Data.html",
    "href": "Data.html",
    "title": "Data, Data, Data",
    "section": "",
    "text": "Introduction:\nWhat Is Data?\n\ndefinition;\ndescription;\ndatasets [pp.16-24 in textbook] - link to from observation to data\n\nCollecting Data\n\npp.16-24 in textbook\n\nData: Some Key Considerations\n\nWhat are you measuring?\nHow are you measuring it?\nHow meaningful are your measures?\n\nIntroduction\nData is the core input of statistics. But more than that, they are the raw material on which the discipline of statistics is built, as well as the raw material from which individual statistics themselves are calculated.\n\n\n\n\n\n\nNote\n\n\n\nThe word data itself comes from the Latin datum, basically meaning “something given”. As such, many people opt to describe data as a plural term (i.e., the data are poor), rather than as a singular (i.e., the data is poor). But it is also common to treat the word data as if it were a continuum. For example, you would never say the water are wet. Rather, you would say water is wet. I tend to jump between both depending on the context.\n\n\nData are typically numbers: the results of measurements, counts, or other processes. But it is not always numbers. Sometimes, data represents categories, or it could even represent plain text, sentences and pictures, depending on the context in which you are working. In saying that, closer examination will usually reveal that when you try to use such data in any type of analysis, it is usually transformed in some way such that it becomes numeric.\nIt is all well-and-good saying that statistics primarily deals with numeric data, but for this data to be useful - that is, for us to be able to do some meaningful analysis - these numbers need to mean something. For example, we need to know, first-and-foremost, what the measurements we have collected are measurements of, and just what has been counted, when data is expressed in counts. Further, to produce reliable and accurate results, we also ought to know a fair deal about how these numbers were collected, alongside who and where they were collected from.\nDid everyone we asked give answers to our questionnaire, or did only some people answer? If only some people answered, are they properly representative of the wider group we wish to study, or has it been distorted in some way? For example, did a disproportionately large number of males answer our survey? Did people only answer specific questions? If so, how do we handle the missing data for the remaining questions? Is there something specific about that question that people did not like, or do these questions appear to have been avoided by specific groups of people (i.e., ethnic minorities).\nLikewise, we need to know if our data is up to date, and whether the measurement instrument we use is reliable. Can we assume that people accurately self-report their income, rent/mortgage payments, and commute times? Or are they better treated as a rough estiminate?\nThere are an infinite number of questions we could ask in this realm. What matters is that we stay alert to any which could influence the conclusions we draw. Failure to consider these questions is what vindicates people who are suspicious of statistics as they constitute a clear failure to apply and interpret the numbers appropriately.\nWith that in mind, another way of thinking about data is to consider it a form of evidence. Without data, our ideas and theories about the world around us are little more than speculations. Data provide a grounding, linking our ideas and theories to reality, while also allowing us to test and validate this understanding. Statistical methods can then be used to compare the data with our ideas and theories, to see how good a match they are. A poor match forces us to think again and reformulate them based on what we observe in the data, while a good match might signal that we have a good intuitive understanding of the problem at hand.\nImplicit in this is that, to be meaningful, our ideas and theories must yield plausible predictions; predictions which we can also compare with our data. If our theories and ideas to do not tell us what we should expect to observe, or if the predictions are so general that any data will conform with our theories (e.g., astrology), then evidently our theories and ideas are no good.\nData also allow us to steer our way through a complex world and make decisions about the best actions to take. We take our measurements, count our totals, and use statistical methods to extract information from these data to describe how the world is behaving and what we should do to make it behave how we want. These principles are illustrated when we seek to evaluate complex regional or social policies.\nData plays a fundamental role in tying observations about the world around us to our ideas and understanding of that world.\nFor example, a relatively basic category like “sex” can take two categories: male and female. Literally speaking, these are words, but when using them in any form of quantitative analysis, they are converted into numbers (usually, 1 and 0), where a value of 1 might represent Males and a value of 0 might represent females or vice versa.\nIn his book, Statistics: A Very Short Introduction, David Hand makes the nice point that even when working with more complicated categories, like entire sentences, these can be processed into word counts, or measures of similarity between words and phrases; and that this is the sort of representation used by search engines like Google.\nI prefer to think of data as an umbrella term capturing any inputs you use when conducting an analysis which contributes to the formation of an answer to your proposed (research) question. In saying that, although many forms of data do not start out as numeric, they will eventually be transformed into numbers, making it somewhat fair to generalise that data is a numeric object; especially seeing as most forms of statistics require numerical data as inputs.\nInsert MCQ - Which of the following might count as “data”, given the above description.\nIt is convenient to think of data as providing a simplified representation of whatever we are studying; be it people, firms, or places. Admittedly, the representation would not be perfect, because many underlying characteristics of people, firms, and places cannot be neatly captured by numeric measures, but they often tell us enough such that the core characteristics of interest can be identified. In saying that, it is important to bear in mind that data quality is extremely important. Like in life, if you have poor material to work with then the results you generate will also be poor. We can do amazing things with statistics, but we cannot perform miracles.\n\nFrom Observation To Data: A Refresher\nSometimes, we observe a single thing — a person, a place, an event — and note several of its features. More interestingly, we often observe many things that are similar in some respects but quite different in others. We notice patterns across people, places, or time. We end up with a collection of observations, or, in the language of statistics, data.\nFaced with such a collection, it is natural to start comparing. What is the same? What is different? What might explain those differences? This is where statistical thinking deepens. The overarching question becomes: what can we learn from this data?\nStatistics helps us summarize what we have found so we can be clear about the facts. But it also helps us go further: to compare, to explain, and to predict. It reminds us to be cautious. What appears true in one context may not hold in another, as I am sure you are all acutely aware. If we want to generalize more confidently, the logical starting point is to gather more experience - that is, collect more data. This speaks to the fact that the more contexts, situations, and experiences we observe, the more confident we can be in drawing conclusions and making suggestions. In other words, if we want to generalize more confidently, we need more data, which happens to be the logic underpinning one of the most powerful ideas in statistics: the Central Limit Theorem."
  }
]